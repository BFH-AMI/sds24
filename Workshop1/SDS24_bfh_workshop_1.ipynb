{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#SDS24 Generative AI for Well-being\n",
        "\n",
        "##Workshop 1: Art therapy simulation"
      ],
      "metadata": {
        "id": "lXhAL0_TCgXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Art Therapy\n"
      ],
      "metadata": {
        "id": "GQf2YR6e0HVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://www.medicalnewstoday.com/articles/art-therapy"
      ],
      "metadata": {
        "id": "R3W9izZ7OcQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Art therapy is* a form of expressive therapy that uses the creative process of making art to improve a person's physical, mental, and emotional well-being. It helps individuals express hidden emotions, enhances self-awareness, and fosters personal growth. Through various art media—be it painting, drawing, or sculpture—patients explore their feelings, reconcile emotional conflicts, manage behavior and addictions, develop social skills, reduce anxiety, and increase self-esteem. This unique therapy integrates psychotherapeutic techniques with the creative process to promote healing and self-expression.\n"
      ],
      "metadata": {
        "id": "vVlraD50DOiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Who is Art Therapy For?"
      ],
      "metadata": {
        "id": "0k7Q98xuB2Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*Art therapy* is a versatile treatment *suitable for* people of all ages, including children, teenagers, adults, and the elderly. It is particularly effective for those who might have difficulty expressing themselves verbally. This therapy can benefit individuals experiencing:\n",
        "- Mental health issues like depression, anxiety, or stress\n",
        "- Behavioral or social problems in children and adolescents\n",
        "- Neurological and cognitive disorders\n",
        "- Chronic health conditions\n",
        "- Trauma and loss\n",
        "- Physical disabilities"
      ],
      "metadata": {
        "id": "85mOIxGFJPyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- Enhances Self-Expression: provides a non-verbal outlet for complex emotions, facilitating easier expression when words are insufficient.\n",
        "- Improves Self-Esteem: encourages a sense of accomplishment through the creation of tangible outcomes and mastering artistic skills.\n",
        "- Reduces Stress: the meditative act of art-making offers significant relaxation, promoting stress reduction and mental clarity.\n",
        "- Encourages Emotional Growth: supports emotional healing and resilience by enabling reflective self-exploration.\n",
        "- Supports Cognitive Function: develops cognitive skills such as problem-solving and planning, applicable in various life aspects.\n",
        "- Promotes Social Skills: fosters interpersonal connections and enhances social skills, especially in group settings."
      ],
      "metadata": {
        "id": "vTLIT3HsLbQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simplified Process of Drawing-Based Art Therapy\n",
        "\n"
      ],
      "metadata": {
        "id": "O1I2yi_nP7yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook guides you through a structured process of art therapy, focusing primarily on drawing. Each step is designed to facilitate emotional exploration and artistic expression in a therapeutic-like setting.\n",
        "\n"
      ],
      "metadata": {
        "id": "WgfIw_e0BmYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By no means this example is intended to try to replace art therapy in any way. But rather we want to use its artistic process to demonstrate possibilities of GenAI within a well-being context**"
      ],
      "metadata": {
        "id": "MD4Yx-bp4Pk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Initial Conversation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5Z7EXd-oBs7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step in art therapy is the initial conversation, which lays the foundation for the therapeutic activity. This step aims to:\n",
        "\n",
        "1. *Explore the Topic*: discuss the issue or theme to explore, including why it was chosen and associated emotions.\n",
        "2. *Visualization*: identify symbols, colors, or images that represent the emotions and topics.\n",
        "3. *Clarification of Feelings*: clarify how the topic feels and the specific images that capture these emotions.\n",
        "\n",
        "In this digital notebook, we adapt the initial conversation by offering:\n",
        "\n",
        "- *Example Persona Stories*: short stories related to different personas to illustrate common emotional scenarios or challenges. These serve as starting points for artistic exploration.\n",
        "- *Personal Art Uploads*: option to upload an image you've created that represents your feelings or thoughts on the topic.\n",
        "- *Interactive Canvas*: a tool to draw directly within the notebook, capturing your immediate emotional responses and artistic impulses.\n"
      ],
      "metadata": {
        "id": "_BzR6NDudsKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Patients' stories\n",
        "\n"
      ],
      "metadata": {
        "id": "emIQGp_Lt7Y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Emily's Journey Through Art Therapy**\n",
        "\n",
        "Emily came to art therapy feeling stuck and unfulfilled in her personal and professional life. Her therapist suggested drawing as a form of self-expression. During one session, Emily drew a woman with a flower blooming from her head, symbolizing personal growth and blossoming ideas. This exercise helped Emily visualize her potential for growth and renewal, leading her to take bold steps towards changing her career path.\n",
        "\n",
        "**Mark's Crossroads**\n",
        "\n",
        "Mark was at a significant crossroad in his life, unsure of whether to continue his corporate job or pursue his passion for music. During a session, he drew a figure standing at a fork in the road, with paths leading into different directions, labeled 'Here' and 'There.' This drawing helped him articulate his dilemma and facilitated a deeper conversation about his true desires, helping him to clarify his next steps.\n",
        "\n",
        "**Linda's Battle with Anxiety**\n",
        "\n",
        "Linda, a dedicated corporate lawyer, often finds herself at the center of high-pressure decisions and stressful scenarios. Despite maintaining a poised exterior, internally, she battles overwhelming chaos. One particularly challenging week, Linda turned to art therapy to express her internal struggle. She created an image of herself with her face buried in her hands, surrounded by chaotic scribbles symbolizing the turmoil in her mind. This artwork serves as a powerful metaphor for the disarray of her thoughts against her outward composure, helping her to recognize and address her mental health challenges."
      ],
      "metadata": {
        "id": "KorKraCyBiw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Initiation of the Artistic Process\n",
        "\n"
      ],
      "metadata": {
        "id": "ypZLGOv0EUPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you've explored the initial concepts and emotions, it's time to bring your insights into tangible form.\n",
        "\n",
        "Focus on being mindful of your emotions and how they manifest in your art. This is key for self-exploration and deepening your connection to your internal landscape.\n",
        "\n",
        "#### Options for Artistic Creation\n",
        "\n",
        "- **Utilizing Pre-existing Images**: you may choose images related to the persona stories, like Emily's \"flower-woman.jpg,\" Mark's \"choice.jpg,\" or Linda's \"chaotic-woman.jpg.\" These images can serve as starting points or inspiration.\n",
        "\n",
        "- **Creating Your Own Artwork**: create your own piece of art using traditional materials or the digital tools in this notebook. This option allows for a deeply personal expression aligned with your feelings and artistic vision.\n",
        "\n",
        "This stage lets you apply your emotional insights creatively. Whether using pre-existing images or starting from scratch, the process enhances your understanding of your emotional responses and artistic expression. This hands-on activity highlights the powerful intersection of AI tools and therapeutic art practices.\n"
      ],
      "metadata": {
        "id": "HhGT_vFzeax7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting Up the Runtime Environment"
      ],
      "metadata": {
        "id": "5TNcCBvg5lEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you start experimenting with this notebook, **it's crucial to set the runtime to use a GPU**. This will ensure that the computations are faster and more efficient. Follow these steps to change the runtime to T4 GPU:\n",
        "\n",
        "1. Click on the arrow next to `RAM` and `Disk` at the top right of the Colab interface.\n",
        "2. Select `Change runtime type` from the dropdown menu.\n",
        "3. In the `Runtime type` dropdown, ensure `Python 3` is selected.\n",
        "4. Under `Hardware accelerator`, choose `T4 GPU`.\n",
        "5. Click `Save` to apply the changes.\n",
        "\n",
        "By setting the runtime to GPU, you will avoid the need to reinstall packages if you initially forget to set it. This will save you time and make the execution of your code faster."
      ],
      "metadata": {
        "id": "qt9PI0Zg5hoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting Up the Drawing Process"
      ],
      "metadata": {
        "id": "WA0Zet5yxQkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting the artistic creation phase, we need to set up our digital environment with the necessary tools. This ensures we can generate and manipulate images using AI.\n",
        "\n",
        "##### Installation of Libraries\n",
        "\n",
        "We will install several key libraries:\n",
        "\n",
        "- *Diffusers*: access state-of-the-art models for image generation (Hugging Face).\n",
        "- *ControlNet_Aux*: customize AI models for specific artistic needs.\n",
        "- *Transformers*: pre-trained models to enhance image generation tasks (Hugging Face).\n",
        "- *Accelerate*: manage model training and usage efficiently.\n",
        "- *SafeTensors*: securely handle data within models.\n",
        "- *Wget*: download files non-interactively, useful for datasets and models.\n",
        "\n",
        "We'll start by executing the following installation commands in the notebook:\n"
      ],
      "metadata": {
        "id": "nP17cACyfYnY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "458oxfAglcKc"
      },
      "outputs": [],
      "source": [
        "!pip install -U git+https://github.com/huggingface/diffusers.git\n",
        "!pip install -U controlnet_aux==0.0.7 # for conditioning models and detectors\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install safetensors\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the necessary libraries installed, we will import various components from the `diffusers` and `controlnet_aux` libraries along with other essential tools:\n",
        "\n",
        "- *StableDiffusionXLAdapterPipeline and T2IAdapter*: generate images from textual descriptions.\n",
        "- *EulerAncestralDiscreteScheduler and AutoencoderKL*: manage and refine image generation during the diffusion process.\n",
        "- *load_image and make_image_grid*: utility functions for loading and arranging images in a grid.\n",
        "- *PidiNetDetector*: detect and condition specific elements within images.\n",
        "- *torch*: handle tensors, core data structures for machine learning and AI.\n",
        "- *random*: generate pseudo-random numbers for various processes.\n",
        "- *numpy*: powerful numerical capabilities for scientific computing.\n"
      ],
      "metadata": {
        "id": "qXWWVOHWgCjp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhMeYKfRllzn"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionXLAdapterPipeline, T2IAdapter, EulerAncestralDiscreteScheduler, AutoencoderKL\n",
        "from diffusers.utils import load_image, make_image_grid\n",
        "from controlnet_aux.pidi import PidiNetDetector\n",
        "import torch\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Setting a Global Seed for Consistency"
      ],
      "metadata": {
        "id": "Gb0WXDYsBRcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure consistent and reproducible images during the workshop, we set a global seed. This makes sure that images generated from the same prompt look identical, no matter when or where the notebook is run, as long as the same seed is used.\n"
      ],
      "metadata": {
        "id": "B2RVviuKgjQK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC9y1XNUDFYI"
      },
      "outputs": [],
      "source": [
        "#setting a seed\n",
        "def set_global_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Setting Up the Image Generation Components"
      ],
      "metadata": {
        "id": "aERQFwXpBM7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In this segment, we configure the essential elements of our image generation pipeline using the Stable Diffusion XL model:\n",
        "\n",
        "1. *Text-to-Image Adapter*: converts text descriptions into image features, optimized for efficient processing on CUDA-enabled devices.\n",
        "2. *Scheduler and Autoencoder*: manages the noise reduction steps and refines image details.\n",
        "3. *Pipeline Assembly*: integrates the adapter, scheduler, and autoencoder into a single, optimized pipeline.\n",
        "4. *PidiNet Detector*: detects and adjusts specific elements in the generated images.\n",
        "5. *Utilizing GPU Acceleration*: moves our model to a GPU for faster processing and efficient handling of complex image generation tasks.\n",
        "\n",
        "For more information, visit the [Hugging Face model page](https://huggingface.co/TencentARC/t2i-adapter-sketch-sdxl-1.0).\n"
      ],
      "metadata": {
        "id": "MZPpWbUYg3WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Text-to-Image adapter with pre-trained settings optimized for sketch outputs\n",
        "adapter = T2IAdapter.from_pretrained(\n",
        "    \"TencentARC/t2i-adapter-sketch-sdxl-1.0\", torch_dtype=torch.float16, varient=\"fp16\"\n",
        ").to('cuda')  # Move the adapter to GPU to leverage faster computing\n",
        "\n",
        "# Load the scheduler used for controlling the diffusion process\n",
        "model_id = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "euler_a = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "\n",
        "# Load the variational autoencoder which refines the image quality\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "\n",
        "# Assemble the components into a pipeline configured for generating images\n",
        "pipeline = StableDiffusionXLAdapterPipeline.from_pretrained(\n",
        "    model_id, vae=vae, adapter=adapter, scheduler=euler_a, torch_dtype=torch.float16, variant=\"fp16\",\n",
        ").to('cuda')\n",
        "\n",
        "# Load the PidiNet Detector for enhancing detection and conditioning capabilities in generated images\n",
        "pidinet = PidiNetDetector.from_pretrained(\"lllyasviel/Annotators\").to('cuda')\n"
      ],
      "metadata": {
        "id": "rxc9Jkq6SAZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import essential libraries for uploading, displaying, and manipulating images:\n",
        "\n",
        "- `google.colab.output`: manages interactive outputs in Google Colab.\n",
        "- `IPython.display`: embeds media like images and HTML.\n",
        "- `PIL`: tools for image processing and manipulation.\n",
        "- `base64`: encodes and decodes binary data to ASCII.\n",
        "- `io`: manages binary data streams for in-memory operations.\n",
        "- `matplotlib.pyplot`: creates visualizations and displays images.\n"
      ],
      "metadata": {
        "id": "7MRjJPv3iFEF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvBreODDuU_n"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "from IPython.display import HTML, display\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
        "import base64\n",
        "import io\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script downloads images from URLs into the Colab content folder using `wget`. A dictionary `images` maps file names to URLs. The script downloads each image and lists the files in the `/content` directory to confirm the downloads.\n"
      ],
      "metadata": {
        "id": "E_xOpojli9KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget          #used for downloading files from the web.\n",
        "\n",
        "# Download the images from web into colab content folder\n",
        "# Define the URLs and corresponding file names for the images\n",
        "images = {\n",
        "    \"flower-woman.jpg\": \"https://github.com/BFH-AMI/sds24/raw/main/Workshop1/images/flower-woman.jpg\",\n",
        "    \"choice.jpg\": \"https://github.com/BFH-AMI/sds24/raw/main/Workshop1/images/choice.jpg\",\n",
        "    \"chaotic-woman.jpg\": \"https://github.com/BFH-AMI/sds24/raw/main/Workshop1/images/chaotic-woman.jpg\"\n",
        "}\n",
        "\n",
        "# Download each image using wget\n",
        "for filename, url in images.items():\n",
        "    wget.download(url, out=f'/content/{filename}')\n",
        "\n",
        "# List the files to confirm download\n",
        "!ls /content"
      ],
      "metadata": {
        "id": "K16Bpjtx7V1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To use pictures associated with the persona stories, uncomment the desired image path by removing the `#` at the beginning of the line.**\n",
        "\n",
        "**If you have drawn a picture and uploaded it to Google Colab, provide the path to your image in the format shown below and uncomment it.**\n"
      ],
      "metadata": {
        "id": "ZFSBSSPIjL9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to Upload an Image in Google Colab**\n",
        "\n",
        "1. Select and click on the folder icon on the left sidebar.\n",
        "2. Click on the upload icon (a paperclip or arrow pointing upward).\n",
        "3. Browse files from your computer, select the desired image, and upload it.\n"
      ],
      "metadata": {
        "id": "KLzne3ZZK10y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrhFZDA0t_Qq"
      },
      "outputs": [],
      "source": [
        "#image_path = '/content/flower-woman.jpg'       # For Emily's Flower-Woman persona story\n",
        "#image_path = '/content/choice.jpg'             # For Mark's Choice persona story\n",
        "#image_path = '/content/chaotic-woman.jpg'       # For Linda's Batte with Anxiety persona story\n",
        "#image_path = '/content/your-image-name.extension'   # Replace with your file's name and extension\n",
        "\n",
        "img = Image.open(image_path)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes for cleaner presentation\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Drawing Directly in the Notebook"
      ],
      "metadata": {
        "id": "D13rHnGlBG6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, you can create a drawing directly in the notebook using an HTML canvas. This allows you to draw freely with your mouse.\n",
        "\n",
        "How It Works:\n",
        "\n",
        "- The canvas has a white background and set dimensions.\n",
        "- Begin drawing by pressing and holding the mouse button while moving the cursor over the canvas.\n",
        "- Release the mouse button to stop drawing; press and hold again to resume.\n",
        "- Click the 'Save' button below the canvas to save your drawing as a PNG file, which will be displayed below the canvas for review.\n"
      ],
      "metadata": {
        "id": "79ajxDa1jek1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "#RUN ONLY IF YOU WANT TO DRAW YOUR SKETCH DIRECTLY IN THE NOTEBOOK\n",
        "######\n",
        "\n",
        "\n",
        "\n",
        "# HTML/JavaScript part\n",
        "canvas_html = \"\"\"\n",
        "\n",
        "<canvas width=\"400\" height=\"300\" style=\"border:1px solid #000000;\"></canvas>\n",
        "<button onclick=\"saveCanvas()\">Save</button>\n",
        "<button onclick=\"clearCanvas()\">Clear</button>\n",
        "<button onclick=\"resizeCanvas(800, 600)\">Large Canvas</button>\n",
        "<button onclick=\"resizeCanvas(400, 300)\">Small Canvas</button>\n",
        "<label for=\"colorPicker\">Color:</label>\n",
        "<input type=\"color\" id=\"colorPicker\">\n",
        "<label for=\"brushSize\">Brush Size:</label>\n",
        "<input type=\"range\" id=\"brushSize\" min=\"1\" max=\"10\" value=\"1\">\n",
        "\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas');\n",
        "var ctx = canvas.getContext('2d');\n",
        "ctx.fillStyle = \"white\";\n",
        "ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "ctx.lineJoin = 'round';\n",
        "ctx.lineCap = 'round';\n",
        "\n",
        "var mouse = {x: 0, y: 0};\n",
        "var last_mouse = {...mouse};\n",
        "var drawing = false;\n",
        "\n",
        "canvas.addEventListener('mousedown', function(e) {\n",
        "    drawing = true;\n",
        "    last_mouse.x = e.pageX - this.offsetLeft;\n",
        "    last_mouse.y = e.pageY - this.offsetTop;\n",
        "    ctx.strokeStyle = document.getElementById('colorPicker').value;\n",
        "    ctx.lineWidth = document.getElementById('brushSize').value;\n",
        "}, false);\n",
        "\n",
        "canvas.addEventListener('mouseup', function() {\n",
        "    drawing = false;\n",
        "}, false);\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "    mouse.x = e.pageX - this.offsetLeft;\n",
        "    mouse.y = e.pageY - this.offsetTop;\n",
        "    if (drawing) {\n",
        "        ctx.beginPath();\n",
        "        ctx.moveTo(last_mouse.x, last_mouse.y);\n",
        "        ctx.lineTo(mouse.x, mouse.y);\n",
        "        ctx.stroke();\n",
        "        last_mouse = {...mouse};\n",
        "    }\n",
        "}, false);\n",
        "\n",
        "function saveCanvas() {\n",
        "    var dataURL = canvas.toDataURL('image/png');\n",
        "    var data = dataURL.split(',')[1];\n",
        "    try {\n",
        "        google.colab.kernel.invokeFunction('notebook.save_image', [data], {});\n",
        "        alert('Image saved successfully!');\n",
        "    } catch (error) {\n",
        "        console.error('Failed to save the image:', error);\n",
        "        alert('Failed to save the image. Please try again.');\n",
        "    }\n",
        "}\n",
        "\n",
        "function clearCanvas() {\n",
        "    ctx.fillStyle = \"white\";\n",
        "    ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "}\n",
        "\n",
        "function resizeCanvas(width, height) {\n",
        "    canvas.width = width;\n",
        "    canvas.height = height;\n",
        "    ctx.fillStyle = \"white\";\n",
        "    ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "# Display the HTML canvas\n",
        "display(HTML(canvas_html))\n",
        "\n",
        "# Function to save the image\n",
        "def save_image(img_str):\n",
        "    # Decode the image string\n",
        "    img_data = base64.b64decode(img_str)\n",
        "    # Convert to a PIL Image\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "    img.save('/content/drawing.png')\n",
        "    # Display the image\n",
        "    display(img)\n",
        "\n",
        "# Register the save function\n",
        "output.register_callback('notebook.save_image', save_image)"
      ],
      "metadata": {
        "id": "tjmhK_s_Y6QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "#RUN ONLY IF YOU WANT TO DRAW YOUR SKETCH DIRECTLY IN THE NOTEBOOK\n",
        "######\n",
        "\n",
        "\n",
        "canvas_drawing_path = '/content/drawing.png'\n",
        "canvas_drawing = Image.open(canvas_drawing_path)\n",
        "img = canvas_drawing"
      ],
      "metadata": {
        "id": "8RE3eLvo8nn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Preprocessing the Image with PidiNet Detector"
      ],
      "metadata": {
        "id": "4smYqWwTBBEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the Text-to-Image (T2I) Adapter effectively, preprocess the image for better edge detection with the PidiNet detector.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1.* Edge Detection*: highlights edges and boundaries.\n",
        "\n",
        "2. *Resolution Settings*:\n",
        "   - `detect_resolution`: higher values give more detailed edges.\n",
        "   - `image_resolution`: sets image size before processing, affecting clarity and detail.\n",
        "3. *Applying Filters* : when `apply_filter` is True, filters like smoothing or denoising reduce noise and enhance edge clarity.\n",
        "\n",
        "After processing, the improved image is displayed.\n"
      ],
      "metadata": {
        "id": "zcMtvLNOlOQ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i2vcc9UyF_U"
      },
      "outputs": [],
      "source": [
        "# Process the image using the PidiNet detector to enhance edge detection\n",
        "processed_image = pidinet(img, detect_resolution=1024, image_resolution=1024, apply_filter=True)\n",
        "\n",
        "# Output the size of the processed image to verify the processing steps\n",
        "print(f\"Processed image size = \", processed_image.size)\n",
        "\n",
        "#Display the processed image\n",
        "display(processed_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating the image"
      ],
      "metadata": {
        "id": "hoYe9msiKIu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the T2I adapter effectively, provide both positive and negative prompts to guide the AI model.\n",
        "\n",
        "Understanding Prompts:\n",
        "- *Positive Prompts*: describe what you want in the image (elements, themes, colors, details).\n",
        "- *Negative Prompts*: describe what you don't want in the image (elements to exclude).\n",
        "\n",
        "**Using Pre-uploaded Images:**\n",
        "- For pre-uploaded images related to persona stories, use the example prompts provided. These align with the themes and narratives of the stories.\n",
        "\n",
        "**Creating Your Own Prompts:**\n",
        "- For Participants Using Sketches or Canvas Drawings: If you created or uploaded your own sketch, write your own prompts to convey the specific emotions and details for your artwork.\n"
      ],
      "metadata": {
        "id": "Q78XhB1EloMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementing the Adapter:"
      ],
      "metadata": {
        "id": "5UPFMKlnA0f3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use your positive and negative prompts with the processed image to guide the T2I adapter.\n",
        "\n",
        "Key Parameters of the adapter:\n",
        "- `num_inference_steps`: more steps can refine the image better.\n",
        "- `adapter_conditioning_scale`: higher values mean the adapter follows the input image and prompts more closely.\n",
        "- `guidance_scale`: higher values mean stricter adherence to the text prompts, leading to images that match the described vision closely.\n"
      ],
      "metadata": {
        "id": "x1ggcVJ-mftC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTvAK377ygEv"
      },
      "outputs": [],
      "source": [
        "########\n",
        "#IF YOU USED POVIDED IMAGES YOU MAY USE FOLLOWING PROMPTS BY UNCOMMENTING THEM\n",
        "########\n",
        "\n",
        "\n",
        "\n",
        "######\n",
        "#FLOWER-WOMAN\n",
        "#EMILY'S JOURNEY THROUGH ART THERAPY\n",
        "#prompt = \"a head of woman in pot, realistic facial features, ranunculus on her head, representing personal growth and renewal, messy background, detailed, high quality\"\n",
        "#negative_prompt = \"empty pot, low resolution, non-realistic, cool background\"\n",
        "#prompt = \"a pot with a realistic human profile, with a vibrant sunflower on her head, symbolizing blossoming ideas and creativity, detailed high-quality, bright, yellow\"\n",
        "#negative_prompt = \"empty pot, simplistic, cartoonish, low resolution\"\n",
        "#prompt = \"artistic portrayal of a woman's profile in a flowerpot with a flowering plant growing from her head, inspiring background, transformation, detailed and vibrant.\"\n",
        "#negative_prompt = \"static scene, monochrome, simplistic elements, low detail.\"\n",
        "#######\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######\n",
        "#CHOICE\n",
        "# MARK'S DESICION-MAKING CROSSROADSM\n",
        "#prompt = \"Man in formal suit, standing at a crossroads, sign reading 'Career' one way, 'Passion' other way, clear paths, thoughtful expression, detailed, high resolution\"\n",
        "#negative_prompt = \"Indistinct man, vague crossroads, no signs, obscured paths, low quality\"\n",
        "#prompt = \"Figure contemplating at a fork in the road, paths labeled 'Here'to office building, 'There' label to music festival, realistic style, detailed, high resolution\"\n",
        "#negative_prompt = \"Unfocused figure, confusing paths, no labels, low quality\"\n",
        "#prompt = \"Businessman at a symbolic crossroad, road sign with 2 directions to office and music festival, detailed, high resolution\"\n",
        "#negative_prompt = \"Vague figure, misleading signs, srene landscape, low quality\"\n",
        "#######\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######\n",
        "#CHAOTIC-WOMAN\n",
        "#LINDA'S ANXIETY BATTLE\n",
        "#prompt = \"Professional woman in a suit with her face buried in her hands, surrounded by chaotic scribbles representing mental stress and anxiety, detailed, high resolution\"\n",
        "#negative_prompt = \"Calm woman, clear background, simple lines, low detail, low resolution\"\n",
        "#prompt = \"Confident woman in business attire with her face in her hands, surrounded by a whirlwind of chaotic lines, symbolizing overwhelming thoughts, high-quality, detailed\"\n",
        "#negative_prompt = \"Relaxed woman, empty background, no chaos, cartoonish, low quality\"\n",
        "#prompt = \"Elegant woman in a tailored suit, face hidden in hands, surrounded by a storm of intersecting lines, embodying the battle with anxiety, artistic, high resolution\"\n",
        "#negative_prompt = \"Casual woman, peaceful expression, simplistic background, no turmoil, low resolution\"\n",
        "#######\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######\n",
        "#IF YOU WANT TO USE YOUR OWN PROMOTS UNCOMMENT THESE\n",
        "#######\n",
        "\n",
        "#YOUR OWN IMAGE\n",
        "#prompt = \"\"\n",
        "#negative_prompt = \"\"\n",
        "#######\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set a global seed for consistency across runs\n",
        "set_global_seeds(42)\n",
        "\n",
        "# Generate the image using the T2I adapter\n",
        "gen_image = pipeline(\n",
        "    prompt=prompt,\n",
        "    negative_prompt = negative_prompt,\n",
        "    image=processed_image,\n",
        "    num_inference_steps=30,         # Default: 50, Min: 1, Max: 50\n",
        "    adapter_conditioning_scale=0.7, # Default: 1.0, Min: 0.0, Max 1.0  # Controls the influence of conditioning on the input\n",
        "    guidance_scale=8,               # Default: 7.5, Min: 0.1, Max: 10.0  # Dictates the adherence to the text prompts\n",
        ").images[0]\n",
        "\n",
        "\n",
        "# Save the generated image\n",
        "gen_image.save('T2ISDXL_sketch.png')\n",
        "T2ISDXL_sketch_path = '/content/T2ISDXL_sketch.png'\n",
        "print(f\"Image saved successfully at {T2ISDXL_sketch_path}\")\n",
        "\n",
        "\n",
        "# Display the saved image\n",
        "plt.imshow(gen_image)\n",
        "plt.axis('off')  # Hide axes for cleaner presentation\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visual Comparison of Original and Generated Images"
      ],
      "metadata": {
        "id": "SWGXGPsaAc5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will display the original image and the generated image side by side. This visual comparison shows how the prompts influenced the final image.\n"
      ],
      "metadata": {
        "id": "KSZXSLuDnGIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "#FOR VISUAL COMPARISON OF THE RESULTS UNCOMMENT OR PROVIDE A CORRECT PASS TO THE ORIGINAL IMAGE\n",
        "######\n",
        "\n",
        "######\n",
        "#UNCOMMENT THE PATH TO THE SELECTED IMAGE\n",
        "######\n",
        "\n",
        "\n",
        "# Define paths to the original and generated images\n",
        "#original_image_path = '/content/flower-woman.jpg'      # FLOWER-WOMAN\n",
        "#original_image_path = '/content/choice.jpg'            # CHOICE\n",
        "#original_image_path = '/content/chaotic-woman.jpg'      #CHAOTIC-WOMAN\n",
        "#original_image_path = '/content/drawing.png'           #IF USED DRAWABLE CANVAS\n",
        "#original_image_path = '/content/your-image-name.extension'    #IF YOU UPLOADED YOUR OWN IMAGE\n",
        "\n",
        "\n",
        "generated_image_path = T2ISDXL_sketch_path\n",
        "\n",
        "\n",
        "# Load the images\n",
        "original_img = Image.open(original_image_path)\n",
        "generated_img = Image.open(generated_image_path)\n",
        "\n",
        "# Create a figure to display both images\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "ax[0].imshow(original_img)\n",
        "ax[0].set_title('Original Image')\n",
        "ax[0].axis('off')  # Hide axes ticks\n",
        "\n",
        "ax[1].imshow(generated_img)\n",
        "ax[1].set_title('Generated Image')\n",
        "ax[1].axis('off')  # Hide axes ticks\n",
        "\n",
        "# Place a text box in bottom left in axes coords for the prompts\n",
        "textstr = f\"Positive Prompt: {prompt}\\nNegative Prompt: {negative_prompt}\"\n",
        "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "fig.text(0.5, 0.02, textstr, fontsize=12, verticalalignment='bottom', horizontalalignment='center', bbox=props)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fxt9kHEpKZJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPU Memory Management in Google Colab\n"
      ],
      "metadata": {
        "id": "yCWnbbrMAgQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "When working with deep learning models in PyTorch within Google Colab, managing GPU memory effectively is crucial to prevent crashes due to memory overflow.\n",
        "\n",
        "Steps to release GPU memory after heavy computations:\n",
        "1. Delete Models and Variables: explicitly remove models and large variables to free their memory.\n",
        "2. Run Garbage Collection: use `gc.collect()` to eliminate unused or unreferenced objects from memory.\n",
        "3. Clear CUDA Cache: execute` torch.cuda.empty_cache() `to clear cached memory that is no longer in use.\n",
        "4. Check Memory Status (Optional): print a memory summary with torch.cuda.memory_summary() to verify that memory has been freed and to understand how memory is allocated.\n",
        "\n",
        "These steps ensure your Colab sessions run smoothly and efficiently, even after processing intensive tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ed37sONjONRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#library responsible for garbige collection\n",
        "import gc\n",
        "\n",
        "# 'adapter', 'pipe', 'pidinet', 'vae', and 'euler_a' are T2I Adapter SDXL model components\n",
        "del adapter\n",
        "del pipeline\n",
        "del pidinet\n",
        "del vae\n",
        "del euler_a"
      ],
      "metadata": {
        "id": "WC8WXx1aO4sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect garbage to free up memory from deleted objects\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "V4xZ-CWfouku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Y_0z_Royoxcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optionally, confirm CUDA memory status\n",
        "print(torch.cuda.memory_summary())"
      ],
      "metadata": {
        "id": "aeeGXkSqpBZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Discussing and Modifying the Artwork Using Inpainting\n"
      ],
      "metadata": {
        "id": "4JEQV9_DXOM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In traditional art therapy, this stage involves discussing the completed artwork to understand the emotions and thoughts it represents. Key focus areas:\n",
        "\n",
        "- *Exploration*: \"What do I notice and feel in this image?\"\n",
        "- *Evaluation*: \"What do I like or dislike? What changes might better convey my feelings?\"\n",
        "\n",
        "Based on this discussion, modifications may be made to explore these insights, such as overpainting, rearranging elements, or cropping.\n",
        "\n",
        "##### Using Generative AI for Modification\n",
        "\n",
        "In our digital simulation, we use generative AI to facilitate artistic modifications:\n",
        "\n",
        "1. *Identify Changes*: decide which parts of the image to change.\n",
        "2. *Text Input for Inpainting*: use example texts or your own descriptions for the changes.\n",
        "3. *Apply Inpainting*: mask the areas to adjust and use inpainting to modify them based on the prompts.\n"
      ],
      "metadata": {
        "id": "0cNBSULen1oJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understanding Inpainting"
      ],
      "metadata": {
        "id": "h2pOXtmRARn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inpainting** is a digital technique for restoring missing or damaged parts of images, making the repairs unnoticeable. It involves:\n",
        "\n",
        "1. Masking: identifying and masking the area to be restored.\n",
        "2. Context Analysis: the AI analyzes the surrounding image for textures, colors, and patterns.\n",
        "3. Texture Synthesis: using generative models to create matching textures.\n",
        "4. Refinement: blending the new section seamlessly with the image.\n",
        "\n",
        "**Applications in Art Therapy**\n",
        "\n",
        "In art therapy, AI-powered inpainting lets clients modify artwork digitally, supporting creative exploration and emotional expression. Clients can make artistic changes without altering the original, fostering deeper engagement with their creative process.\n"
      ],
      "metadata": {
        "id": "gkQpvKKvoi-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The following Python code uses the `diffusers` library to set up an inpainting pipeline. This setup allows us to apply inpainting to images.\n",
        "\n",
        "##### Importing Necessary Modules:\n",
        "   - `AutoPipelineForInpainting`: this function from the `diffusers` library loads a pre-trained inpainting model. It's designed to handle the process of masking and generating the inpainted output.\n",
        "   - `load_image`: a utility to load images into a format that can be processed by the pipeline.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ww6JyZl9ZyP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForInpainting\n",
        "from diffusers.utils import load_image"
      ],
      "metadata": {
        "id": "M8fQG7X2kLzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Setting Up the Inpainting Pipeline"
      ],
      "metadata": {
        "id": "8EUrlBRdACMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below sets up the inpainting pipeline using a pre-trained model:\n",
        "\n",
        "- *Model Loading:* Loads the \"kandinsky-community/kandinsky-2-2-decoder-inpaint\" model from Hugging Face, designed for inpainting tasks.\n",
        "- *Model Configuration*: Uses `torch.float16` for calculations to reduce memory and computational needs.\n",
        "- *Device Assignment*: Runs on a CUDA-enabled GPU (`to('cuda')`) for faster processing.\n",
        "\n",
        "For more information, visit the [Hugging Face page](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint).\n"
      ],
      "metadata": {
        "id": "NglXXdEVpSzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing pipline\n",
        "pipeline = AutoPipelineForInpainting.from_pretrained(\n",
        "    \"kandinsky-community/kandinsky-2-2-decoder-inpaint\", torch_dtype=torch.float16\n",
        ").to('cuda')"
      ],
      "metadata": {
        "id": "YkRYv6fikEG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Image Loading and Preprocessing"
      ],
      "metadata": {
        "id": "Z6oR0La2_85A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we load and prepare an image for the inpainting task:\n",
        "\n",
        "- *Image Path Setup*: specify the path to the image file, `T2ISDXL_sketch_canvas_1.png`, stored in the `/content` directory.\n",
        "- *Image Loading*: open the image using Python's `Image` module from the PIL (Pillow) library.\n",
        "- *Image Resizing*: resize the image to 1024x1024 pixels for consistency and optimized processing.\n",
        "- *Image Dimensions*: retrieve and store the dimensions of the resized image for further processing.\n",
        "- *Image Encoding to Bytes*: convert the image to bytes format, necessary for encoding.\n",
        "- *Base64 Encoding*: encode the image bytes into Base64 for easy transmission and embedding.\n",
        "\n",
        "This sequence of operations prepares the image for the inpainting process, ensuring it is in the correct format and size for efficient processing.\n"
      ],
      "metadata": {
        "id": "FIauD8e4qC97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path for the image to be loaded\n",
        "T2ISDXL_sketch_path = '/content/T2ISDXL_sketch.png'\n",
        "\n",
        "# Open the image file using Pillow's Image module\n",
        "T2ISDXL_sketch = Image.open(T2ISDXL_sketch_path)\n",
        "\n",
        "# Retrieve and store the dimensions of the original image\n",
        "original_width, original_height = T2ISDXL_sketch.size\n",
        "\n",
        "# Determine the aspect ratio of the image\n",
        "aspect_ratio = original_width / original_height\n",
        "\n",
        "# Resize the image based on its aspect ratio\n",
        "if aspect_ratio > 1:\n",
        "    # If the image is horizontal\n",
        "    new_width = 1024\n",
        "    new_height = int(1024 / aspect_ratio)\n",
        "else:\n",
        "    # If the image is quadratic or vertical\n",
        "    new_width = int(1024 * aspect_ratio)\n",
        "    new_height = 1024\n",
        "\n",
        "# Resize the image for consistent processing\n",
        "img = T2ISDXL_sketch.resize((new_width, new_height))\n",
        "\n",
        "# Retrieve and store the dimensions of the resized image\n",
        "image_width, image_height = img.size\n",
        "\n",
        "# Create a buffer to hold the bytes of the image\n",
        "img_bytes = io.BytesIO()\n",
        "\n",
        "# Save the image to the buffer in JPEG format\n",
        "img.save(img_bytes, format='JPEG')\n",
        "\n",
        "# Encode the image bytes to Base64 to facilitate easy text-based storage or transmission\n",
        "img_b64 = base64.b64encode(img_bytes.getvalue()).decode('ascii')\n"
      ],
      "metadata": {
        "id": "WMcO9fN7QAHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interactive Image Modification with Drawable Canvas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JhYlTMaVdL4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we use an interactive canvas to modify an image by drawing directly on it. This feature is useful in art therapy, allowing dynamic and intuitive artwork changes.\n",
        "\n",
        "Canvas and Drawing Functionality\n",
        "\n",
        "- *Canvas Setup*: a canvas is layered over the image for precise modifications.\n",
        "- *Drawing Tools*: draw on the canvas with simple mouse actions.\n",
        "- *Saving Modifications*: a 'Save' button captures your drawing and saves it as a PNG image.\n",
        "\n",
        "Mask Creation and Its Roles\n",
        "\n",
        "- *Transparent Mask*: creates a transparent background where no drawing is present.\n",
        "- *White Background Mask*: places the transparent drawing over a white background for visibility.\n",
        "- *Inverted Mask*: inverts the white background mask to define areas needing modification.\n",
        "\n",
        "This process allows you to explore and implement changes to your artwork effectively.\n"
      ],
      "metadata": {
        "id": "-COO9I93qbl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "canvas_html = f\"\"\"\n",
        "<div style=\"position: relative; width: {image_width}px; height: {image_height}px;\">\n",
        "  <img src=\"data:image/jpeg;base64,{img_b64}\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\">\n",
        "  <canvas id=\"drawingCanvas\" width=\"{image_width}\" height=\"{image_height}\" style=\"position: absolute; top: 0; left: 0; border:1px solid #000000;\"></canvas>\n",
        "</div>\n",
        "<label>Brush Size:</label>\n",
        "<input type=\"range\" id=\"brushSize\" min=\"1\" max=\"50\" value=\"10\" onchange=\"updateBrushSize()\">\n",
        "<button onclick=\"clearCanvas()\">Clear</button>\n",
        "<button onclick=\"saveCanvas()\">Save</button>\n",
        "<script>\n",
        "var canvas = document.getElementById('drawingCanvas');\n",
        "var ctx = canvas.getContext('2d');\n",
        "var brushSize = 10;  // Initialize brush size\n",
        "var mouse = {{x: 0, y: 0}};\n",
        "var last_mouse = {{x: 0, y: 0}};\n",
        "var drawing = false;\n",
        "\n",
        "// Update brush size\n",
        "function updateBrushSize() {{\n",
        "    brushSize = document.getElementById('brushSize').value;\n",
        "}}\n",
        "\n",
        "// Clear the canvas\n",
        "function clearCanvas() {{\n",
        "    ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "}}\n",
        "\n",
        "canvas.addEventListener('mousedown', function(e) {{\n",
        "    drawing = true;\n",
        "    last_mouse.x = e.pageX - this.offsetLeft;\n",
        "    last_mouse.y = e.pageY - this.offsetTop;\n",
        "    ctx.lineWidth = brushSize;\n",
        "}}, false);\n",
        "\n",
        "canvas.addEventListener('mouseup', function() {{\n",
        "    drawing = false;\n",
        "}}, false);\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {{\n",
        "    mouse.x = e.pageX - this.offsetLeft;\n",
        "    mouse.y = e.pageY - this.offsetTop;\n",
        "    if (drawing) {{\n",
        "        ctx.beginPath();\n",
        "        ctx.moveTo(last_mouse.x, last_mouse.y);\n",
        "        ctx.lineTo(mouse.x, mouse.y);\n",
        "        ctx.lineWidth = brushSize;\n",
        "        ctx.lineCap = \"round\";\n",
        "        ctx.strokeStyle = \"black\";\n",
        "        ctx.stroke();\n",
        "        last_mouse.x = mouse.x;\n",
        "        last_mouse.y = mouse.y;\n",
        "    }}\n",
        "}}, false);\n",
        "\n",
        "function saveCanvas() {{\n",
        "    var dataURL = canvas.toDataURL('image/png');\n",
        "    var data = dataURL.split(',')[1];\n",
        "    google.colab.kernel.invokeFunction('notebook.save_image', [data], {{}});\n",
        "}}\n",
        "</script>\n",
        "\"\"\"\n",
        "# Display the HTML canvas\n",
        "display(HTML(canvas_html))\n",
        "\n",
        "# Function to save the image and process it for creating a mask\n",
        "def save_image(img_str):\n",
        "    # Decode the image string to binary data\n",
        "    img_data = base64.b64decode(img_str)\n",
        "    # Convert the binary data to a PIL Image\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "    img.save('/content/drawing.png') # Save the initial drawing\n",
        "\n",
        "    # Create and save a new image with a white background\n",
        "    new_img = Image.new('RGBA', img.size, (255, 255, 255, 255))\n",
        "    new_img.save(\"white.png\")\n",
        "\n",
        "    white_image = Image.open('white.png')\n",
        "    transparent_image = img\n",
        "\n",
        "    # Ensure the image is in RGBA format for proper compositing\n",
        "    if transparent_image.mode != 'RGBA':\n",
        "        transparent_image = transparent_image.convert('RGBA')\n",
        "\n",
        "    # Composite the transparent image over the white background\n",
        "    white_image.paste(transparent_image, (0, 0), transparent_image)\n",
        "    white_image = white_image.convert('RGB')\n",
        "\n",
        "    # Invert the image colors to create a mask\n",
        "    inverted_img = ImageOps.invert(white_image)\n",
        "    inverted_img.save('mask_image.png') # Save the final mask\n",
        "    print(\"Mask saved\")\n",
        "    display(inverted_img) # Display the mask image\n",
        "\n",
        "# Register the save function to allow invocation from JavaScript\n",
        "output.register_callback('notebook.save_image', save_image)\n"
      ],
      "metadata": {
        "id": "5uE_D10h7mOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drawing = Image.open('/content/T2ISDXL_sketch.png')  #Adjust if needed\n",
        "mask_image = Image.open('/content/mask_image.png')\n",
        "white = Image.open('/content/white.png')\n",
        "\n",
        "# Set up a matplotlib subplot with 3 rows to display the images\n",
        "fig, axs = plt.subplots(2, figsize=(10, 15))  # Adjust figsize to ensure images are not too small\n",
        "\n",
        "# Display the original drawing in the first subplot\n",
        "axs[0].imshow(drawing)\n",
        "axs[0].set_title('Original Drawing')\n",
        "axs[0].axis('off')  # Turn off axis to focus on the image\n",
        "\n",
        "# Display the mask image in the second subplot\n",
        "axs[1].imshow(mask_image)\n",
        "axs[1].set_title('Mask Image')\n",
        "axs[1].axis('off')\n",
        "\n",
        "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
        "plt.show()  # Show the plots"
      ],
      "metadata": {
        "id": "0mzvgjf7g0OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementing the Inpainting Pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "6RUGe-QEoLZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following steps, use the inpainting pipeline to alter parts of your image where you've applied a mask:\n",
        "\n",
        "- Use the example prompts by uncommenting them or create your own based on previous modifications.\n",
        "\n",
        "- Set a seed with `set_global_seeds(42)` to ensure consistent results.\n",
        "\n",
        "- With your prompt, the pipeline  fill in masked areas. Adjust `strength` to control the blend between inpainted and original areas,  `guidance_scale` determines how closely the inpainting follows your prompt.\n"
      ],
      "metadata": {
        "id": "KknmouiXq9e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example prompts\n",
        "#flower-woman\n",
        "#prompt = \"Woman with a long, flowing hairstyle, adding waves and volume”\n",
        "#prompt = \"Woman with golden, flowing dress, matching style and hue\"\n",
        "#prompt = \"Transform the background into a serene, inspiring natural scene with soft, evening lighting to reflect a calm and nurturing environment for growth.\"\n",
        "\n",
        "\n",
        "#choice\n",
        "#prompt = \"stormy sky, lightning, thunder, pouring, detailed\"\n",
        "#prompt = \"Digital information panel, interactive touch screen, contemporary design\"\n",
        "#prompt = \"Rolling mountain landscape, lush green grass, wildflowers, scenic vista, tranquil nature\"\n",
        "\n",
        "#chaotic-woman\n",
        "# prompt = \"Gentle waterfall flowing from the chaotic lines, clear water symbolizing mental clarity and refreshment\"\n",
        "# prompt = \"Bright galaxy emerging from the scribbles, spiraling arms radiating calm and order, representing Ava's journey to tranquility\"\n",
        "#prompt = \"Glowing lotus blossoming from the tangled lines, petals unfolding smoothly, symbolizing peace and spiritual awakening\"\n",
        "\n",
        "#your prompt\n",
        "#prompt = \"stormy sky, lightning, thunder, pouring, detailed\"\n",
        "\n",
        "\n",
        "# Set a consistent seed for reproducibility\n",
        "set_global_seeds(42)\n",
        "\n",
        "\n",
        "#Initiating inpainting pipline\n",
        "image = pipeline(\n",
        "    prompt=prompt,\n",
        "    #negative_prompt=negative_prompt,\n",
        "    image=img,\n",
        "    mask_image=mask_image,\n",
        "    strength=0.7,                   # Default: 0.75, Min: 0.0, Max: 1.0  # How separate the infill is to the rest of the image\n",
        "    guidance_scale=9,               # Default: 4.0, Min: 1.0, Max: 20.0  # How important the prompt is\n",
        "    num_inference_steps=50,         # Default: 100, Min: 1, Max: 1000   # Number of denoising steps\n",
        "  ).images[0]\n",
        "\n",
        "\n",
        "# Save the generated image\n",
        "image.save('image_inpainting.png')\n",
        "\n",
        "# Save and display the final image with proper size\n",
        "final_image = Image.open('image_inpainting.png')\n",
        "final_image = final_image.resize((new_width, new_height))\n",
        "\n",
        "# Save the final resized image to the content folder\n",
        "final_resized_image_path = '/content/final_resized_image.png'\n",
        "final_image.save(final_resized_image_path)\n",
        "\n",
        "# Display the final resized image (optional)\n",
        "plt.imshow(final_image)\n",
        "plt.axis('off')                              # Hide axes for cleaner presentation\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YEzl-_7yki-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visual Comparison of Art Therapy Session Outcomes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i8d7gsxULfVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we'll compare the transformation of images through our art therapy simulation using  GenAI. This comparison highlights the progression from:\n",
        "\n",
        "1. Original Image: the starting artwork.\n",
        "2. After Applying Adapter: modifications by the T2I adapter based on your prompts.\n",
        "3. Final Inpainted Image: the end result after inpainting.\n",
        "\n",
        "By examining these stages side by side, we gain insights into the AI's interpretative capabilities and its effectiveness in enhancing artistic expressions. This comparison serves as a foundation for further discussion.\n"
      ],
      "metadata": {
        "id": "ogIJaon3rXSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "#FOR VISUAL COMPARISON OF THE RESULTS UNCOMMENT OR PROVIDE A CORRECT PASS TO THE ORIGINAL IMAGE\n",
        "######\n",
        "\n",
        "\n",
        "######\n",
        "#UNCOMMENT THE PATH  BELOW TO THE IMAGE USED\n",
        "######\n",
        "\n",
        "# Define paths to the original and generated images\n",
        "#original_image_path = '/content/flower-woman.jpg'      # FLOWER-WOMAN\n",
        "#original_image_path = '/content/choice.jpg'            # CHOICE\n",
        "#original_image_path = '/content/chaotic-woman.jpg'      #CHAOTIC-WOMAN\n",
        "#original_image_path = '/content/drawing.png'           #IF USED DRAWABLE CANVAS\n",
        "#original_image_path = '/content/your-image-name.extension'    #IF YOU UPLOADED YOUR OWN IMAGE\n",
        "\n",
        "\n",
        "\n",
        "adapted_image_path = '/content/T2ISDXL_sketch.png'  # PATH TO THE IMAGE AFTER APPLYING ADAPTER\n",
        "inpainting_image = '/content/final_resized_image.png'  # PATH TO AFTER INPAINTING IMAGE\n",
        "\n",
        "\n",
        "\n",
        "# Load images using PIL\n",
        "original_img = Image.open(original_image_path)\n",
        "adapted_img = Image.open(adapted_image_path)\n",
        "inpainting_img = Image.open(inpainting_image)\n",
        "\n",
        "# Create a matplotlib figure to display the images\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 6))  # Setting up a figure with 3 subplots\n",
        "\n",
        "# Display Original Image\n",
        "ax[0].imshow(original_img)\n",
        "ax[0].set_title('Original Image')\n",
        "ax[0].axis('off')  # Turn off axis\n",
        "\n",
        "# Display Image after Adapter\n",
        "ax[1].imshow(adapted_img)\n",
        "ax[1].set_title('After Applying Adapter')\n",
        "ax[1].axis('off')  # Turn off axis\n",
        "\n",
        "# Display Final Inpainted Image\n",
        "ax[2].imshow(inpainting_img)\n",
        "ax[2].set_title('Final Inpainted Image')\n",
        "ax[2].axis('off')  # Turn off axis\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WVPmmDUCMDnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPU Memory Cleanup\n",
        "\n",
        "Post-inpainting, it's important to clean up GPU memory to maintain optimal performance. Here’s a quick way to do it:\n"
      ],
      "metadata": {
        "id": "S9rTYKaeOcd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del pipeline"
      ],
      "metadata": {
        "id": "fb11oA3POiQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect garbage to free up memory from deleted objects\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "_e6AjwAr1ns6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "quL48TIg1pEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, confirm CUDA memory status\n",
        "print(torch.cuda.memory_summary())"
      ],
      "metadata": {
        "id": "jPE0fR-Z1p_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion and Discussion\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mZAbZbHaPsk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We encourage you to experiment with different image prompts and parameters in the generative models we've explored. How might altering these inputs influence the output, and what does this tell us about the interaction between technology and creative expression?\n",
        "\n",
        "To ensure you can continue experimenting without exceeding the GPU usage limits of the platform, remember to manage resources effectively. After each inference test, consider using `gc.collect()` to run garbage collection and `torch.cuda.empty_cache()` to clear the CUDA cache. This practice helps in preventing memory overflow and allows for sustained experimentation.\n"
      ],
      "metadata": {
        "id": "WUXp098z_GTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Key Takeaways from the Workshop:\n",
        "\n",
        "- *Enhancement of Creative Expression*: GenAI tools like the inpainting pipeline help artists and non-artists expand their creative boundaries, offering new ways to visualize emotions and concepts.\n",
        "- *Accessibility and Inclusivity*: GenAI makes artistic expression more accessible, promoting inclusivity for individuals without traditional artistic skills.\n",
        "- *Therapeutic Potential*: creating art with GenAI can have therapeutic benefits, helping individuals express themselves in new ways.\n",
        "\n",
        "##### Limitations of GenAI in Art Therapy Simulations:\n",
        "\n",
        "- *Emotional Resonance*: GenAI art may lack the emotional depth and personal touch of human-created art, which is crucial in therapeutic settings.\n",
        "- *Individualization*: GenAI may struggle to fully understand and adapt to the unique emotional and psychological needs of each individual.\n",
        "- *Resource Intensive*: running GenAI models requires significant computational resources, potentially limiting access for smaller therapy practices.\n",
        "\n",
        "##### Open Questions:\n",
        "\n",
        "- How might we address these challenges to enhance the benefits of GenAI in art therapy?\n",
        "- Do you see a potential of using GenAI in the real world environment?\n"
      ],
      "metadata": {
        "id": "JKPcZyRXshr8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0k7Q98xuB2Ne",
        "O1I2yi_nP7yt",
        "emIQGp_Lt7Y5",
        "5TNcCBvg5lEs"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}