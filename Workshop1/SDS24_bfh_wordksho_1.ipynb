{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Art therapy simulation"
   ],
   "metadata": {
    "id": "lXhAL0_TCgXV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding Art Therapy\n"
   ],
   "metadata": {
    "id": "GQf2YR6e0HVN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Source: https://www.medicalnewstoday.com/articles/art-therapy"
   ],
   "metadata": {
    "id": "R3W9izZ7OcQJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Art therapy is* a form of expressive therapy that uses the creative process of making art to improve a person's physical, mental, and emotional well-being. It helps individuals express hidden emotions, enhances self-awareness, and fosters personal growth. Through various art media—be it painting, drawing, or sculpture—patients explore their feelings, reconcile emotional conflicts, manage behavior and addictions, develop social skills, reduce anxiety, and increase self-esteem. This unique therapy integrates psychotherapeutic techniques with the creative process to promote healing and self-expression.\n"
   ],
   "metadata": {
    "id": "vVlraD50DOiF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Who is Art Therapy For?"
   ],
   "metadata": {
    "id": "0k7Q98xuB2Ne"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "*Art therapy* is a versatile treatment *suitable for* people of all ages, including children, teenagers, adults, and the elderly. It is particularly effective for those who might have difficulty expressing themselves verbally. This therapy can benefit individuals experiencing:\n",
    "- Mental health issues like depression, anxiety, or stress\n",
    "- Behavioral or social problems in children and adolescents\n",
    "- Neurological and cognitive disorders\n",
    "- Chronic health conditions\n",
    "- Trauma and loss\n",
    "- Physical disabilities"
   ],
   "metadata": {
    "id": "85mOIxGFJPyK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Benefits of Art Therapy"
   ],
   "metadata": {
    "id": "-y8LGgQWB0AT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "- Enhances Self-Expression: provides a non-verbal outlet for complex emotions, facilitating easier expression when words are insufficient.\n",
    "- Improves Self-Esteem: encourages a sense of accomplishment through the creation of tangible outcomes and mastering artistic skills.\n",
    "- Reduces Stress: the meditative act of art-making offers significant relaxation, promoting stress reduction and mental clarity.\n",
    "- Encourages Emotional Growth: supports emotional healing and resilience by enabling reflective self-exploration.\n",
    "- Supports Cognitive Function: develops cognitive skills such as problem-solving and planning, applicable in various life aspects.\n",
    "- Promotes Social Skills: fosters interpersonal connections and enhances social skills, especially in group settings."
   ],
   "metadata": {
    "id": "vTLIT3HsLbQZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Simplified Process of Drawing-Based Art Therapy\n",
    "\n"
   ],
   "metadata": {
    "id": "O1I2yi_nP7yt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook guides you through a structured process of art therapy, focusing primarily on drawing. Each step is designed to facilitate emotional exploration and artistic expression in a therapeutic-like setting.\n",
    "\n"
   ],
   "metadata": {
    "id": "WgfIw_e0BmYs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**By no means this example is intended to try to replace art therapy in any way. But rather we want to use its artistic process to demonstrate possibilities of GenAI within a well-being context**"
   ],
   "metadata": {
    "id": "MD4Yx-bp4Pk2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Initial Conversation\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "5Z7EXd-oBs7P"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The first step in the art therapy process is typically the initial conversation, which helps set the foundation for the therapeutic activity. This conversation aims to:\n",
    "\n",
    "1. **Explore the Topic**: The client discusses the issue or theme they want to explore. This involves explaining why they chose this topic and what emotions are associated with it.\n",
    "2. **Visualization**: Discuss how these emotions and topics might be visually represented. What symbols, colors, or images come to mind when thinking about these feelings?\n",
    "3. **Clarification of Feelings**: Further clarify how the topic feels and which specific images appear in the client's mind that might capture these emotions.\n",
    "\n",
    "In this digital notebook format, we adapt this initial conversation by offering:\n",
    "- **Example Persona Stories**: You can choose from short stories related to different personas, which illustrate common emotional scenarios or challenges. These stories serve as a starting point for your artistic exploration.\n",
    "- **Personal Art Uploads**: Alternatively, you have the option to upload an image that you've created which represents your feelings or thoughts regarding the topic.\n",
    "- **Interactive Canvas**: For those who prefer to create something new in the moment, an interactive HTML canvas is available right in the notebook. This tool allows you to draw directly within this digital environment, capturing your immediate emotional responses and artistic impulses.\n",
    "\n"
   ],
   "metadata": {
    "id": "KNM2uWEmBusW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Patients' stories\n",
    "\n"
   ],
   "metadata": {
    "id": "emIQGp_Lt7Y5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Emily's Journey Through Art Therapy**\n",
    "\n",
    "Emily came to art therapy feeling stuck and unfulfilled in her personal and professional life. Her therapist suggested drawing as a form of self-expression. During one session, Emily drew a woman with a flower blooming from her head, symbolizing personal growth and blossoming ideas. This exercise helped Emily visualize her potential for growth and renewal, leading her to take bold steps towards changing her career path.\n",
    "\n",
    "**Mark's Crossroads**\n",
    "\n",
    "Mark was at a significant crossroad in his life, unsure of whether to continue his corporate job or pursue his passion for music. During a session, he drew a figure standing at a fork in the road, with paths leading into different directions, labeled 'Here' and 'There.' This drawing helped him articulate his dilemma and facilitated a deeper conversation about his true desires, helping him to clarify his next steps.\n",
    "\n",
    "**Linda's Battle with Anxiety**\n",
    "\n",
    "Linda, a dedicated corporate lawyer, often finds herself at the center of high-pressure decisions and stressful scenarios. Despite maintaining a poised exterior, internally, she battles overwhelming chaos. One particularly challenging week, Linda turned to art therapy to express her internal struggle. She created an image of herself with her face buried in her hands, surrounded by chaotic scribbles symbolizing the turmoil in her mind. This artwork serves as a powerful metaphor for the disarray of her thoughts against her outward composure, helping her to recognize and address her mental health challenges."
   ],
   "metadata": {
    "id": "KorKraCyBiw0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Initiation of the Artistic Process\n",
    "\n"
   ],
   "metadata": {
    "id": "ypZLGOv0EUPY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that you've explored the initial concepts and emotions, it's time to bring your insights into tangible form.\n",
    "\n",
    "#### During the Artistic Creation:\n",
    "As you begin to paint or draw, focus on being mindful of your emotions and how they manifest in your art. This is a key moment for self-exploration and deepening your connection to your internal landscape.\n",
    "\n",
    "#### Options for Artistic Creation:\n",
    "- **Utilizing Pre-existing Images:** You may choose to work with images that relate to the persona stories we've explored, such as Emily's \"flower-woman.jpg\" or Mark's \"choice.png\", or Linda's \"chaos&clarity.png\". These images can serve as a starting point or inspiration for further creative exploration.\n",
    "\n",
    "- **Creating Your Own Artwork:** Alternatively, you are encouraged to create your own piece of art. Whether using traditional materials or the digital tools available in this notebook, this option allows for a deeply personal expression that can align more closely with your feelings and artistic vision.\n",
    "\n",
    "This stage of the workshop allows you to apply your emotional insights creatively. Whether you’re building on pre-existing images or starting from scratch, the process is designed to enhance your understanding of your emotional responses and artistic expression. This hands-on activity is central to our workshop, highlighting the powerful intersection of AI tools and therapeutic art practices.\n"
   ],
   "metadata": {
    "id": "DDmScDZMBbja"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setting Up the Runtime Environment"
   ],
   "metadata": {
    "id": "5TNcCBvg5lEs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before you start experimenting with this notebook, it's crucial to set the runtime to use a GPU. This will ensure that the computations are faster and more efficient. Follow these steps to change the runtime to T4 GPU:\n",
    "\n",
    "1. Click on the arrow next to `RAM` and `Disk` at the top right of the Colab interface.\n",
    "2. Select `Change runtime type` from the dropdown menu.\n",
    "3. In the `Runtime type` dropdown, ensure `Python 3` is selected.\n",
    "4. Under `Hardware accelerator`, choose `T4 GPU`.\n",
    "5. Click `Save` to apply the changes.\n",
    "\n",
    "By setting the runtime to GPU, you will avoid the need to reinstall packages if you initially forget to set it. This will save you time and make the execution of your code faster."
   ],
   "metadata": {
    "id": "qt9PI0Zg5hoH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setting Up the Drawing Process"
   ],
   "metadata": {
    "id": "WA0Zet5yxQkT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Before diving into the artistic creation phase, it's crucial to set up our digital environment with the necessary tools. This setup ensures that we have all the advanced functionalities at our disposal for generating and manipulating images using AI.\n",
    "\n",
    "**Installation of Libraries:**\n",
    "We will install several key libraries to facilitate this process:\n",
    "\n",
    "- **Diffusers**: This library by Hugging Face is central to accessing state-of-the-art models for image generation, which will be instrumental in creating AI-driven artwork.\n",
    "- **ControlNet_Aux**: Essential for conditioning models and detectors, this library helps customize AI models to suit our specific artistic needs.\n",
    "- **Transformers**: Also from Hugging Face, this provides a suite of pre-trained models that can be adapted to enhance our image generation tasks.\n",
    "- **Accelerate**: Helps efficiently manage model training and usage across various hardware setups, ensuring smooth performance.\n",
    "- **SafeTensors**: Secures the handling of data within models, maintaining the integrity and safety of our digital artwork processes.\n",
    "\n",
    "We'll begin by executing the following installation commands in the notebook:\n"
   ],
   "metadata": {
    "id": "1o0X-d4GFz8l"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "458oxfAglcKc"
   },
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/huggingface/diffusers.git\n",
    "!pip install -U controlnet_aux==0.0.7 # for conditioning models and detectors\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install safetensors\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the necessary libraries installed, we now proceed to import specific tools and models that will enable us to harness the power of AI for creating and refining artwork.\n",
    "\n",
    "We will import various components from the `diffusers` and `controlnet_aux` libraries along with other essential tools:\n",
    "\n",
    "- **StableDiffusionXLAdapterPipeline and T2IAdapter**: These classes from the `diffusers` library allow us to generate images based on textual descriptions, providing a seamless integration of textual inputs to visual outputs.\n",
    "- **EulerAncestralDiscreteScheduler and AutoencoderKL**: Essential for managing how images are progressively generated and refined during the diffusion process, ensuring high-quality results.\n",
    "- **load_image and make_image_grid**: Utility functions from `diffusers` that help in loading images for processing and arranging multiple images in a grid for easy visualization.\n",
    "- **PidiNetDetector**: A component from `controlnet_aux` designed for detecting and conditioning specific elements within images, enhancing our ability to tailor the AI's output to our artistic vision.\n",
    "- **torch**: The foundational library for handling tensors, which are the core data structures used in machine learning and AI applications.\n",
    "- **random**: This module from Python's standard library is used to generate pseudo-random numbers for various randomization processes. It is essential in scenarios where you need to introduce variability or randomness, such as in sampling or data shuffling, ensuring that the outputs can be diverse yet predictable when seeded.\n",
    "- **numpy**: Known for its powerful numerical capabilities, numpy is the fundamental package for scientific computing with Python."
   ],
   "metadata": {
    "id": "WMzUpJq4HqtT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhMeYKfRllzn"
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLAdapterPipeline, T2IAdapter, EulerAncestralDiscreteScheduler, AutoencoderKL\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "from controlnet_aux.pidi import PidiNetDetector\n",
    "import torch\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "####Setting a Global Seed for Consistency"
   ],
   "metadata": {
    "id": "Gb0WXDYsBRcf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "To ensure that the images generated during our workshop are consistent and reproducible, we set a global seed. By standardizing these random processes, the images generated from the same prompt will look identical, regardless of when or where the notebook is run, provided the same seed is used.\n",
    "\n"
   ],
   "metadata": {
    "id": "WQESov9iJTVC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UC9y1XNUDFYI"
   },
   "outputs": [],
   "source": [
    "#setting a seed\n",
    "def set_global_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "####Setting Up the Image Generation Components"
   ],
   "metadata": {
    "id": "aERQFwXpBM7w"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "In this segment, we configure the essential elements of our image generation pipeline using the Stable Diffusion XL model:\n",
    "\n",
    "1. **Text-to-Image Adapter**: We load a specialized adapter that converts textual descriptions into image features, specifically tuned for sketch-based outputs. This adapter utilizes half-precision floating point (FP16) for efficient processing on CUDA-enabled devices.\n",
    "\n",
    "2. **Scheduler and Autoencoder**: The diffusion process is orchestrated by the Euler Ancestral Discrete Scheduler which manages the noise reduction steps crucial for generating images. Simultaneously, the Autoencoder KL, optimized for FP16, refines image details through its encoding and decoding capabilities.\n",
    "\n",
    "3. **Pipeline Assembly**: All these components—the adapter, scheduler, and autoencoder—are integrated into a single pipeline. This setup not only streamlines the image generation process but also ensures that it is optimized for high performance on GPUs.\n",
    "\n",
    "4. **PidiNet Detector**: To further refine our outputs and tailor the AI’s response to specific artistic needs, the PidiNet Detector is included. This tool enhances the capability to detect and adjust specific elements within the generated images, aligning closely with the intended artistic vision.\n",
    "\n",
    "5. **Utilizing GPU Acceleration**: The addition of `.to('cuda')` to our components instructs the system to utilize NVIDIA CUDA technology for processing. This command moves our model and its computations to a GPU, if available, enabling faster processing times and more efficient handling of large neural network operations which are common in AI-driven image generation. This GPU acceleration is crucial for real-time interaction and high-speed rendering of complex images.\n",
    "\n"
   ],
   "metadata": {
    "id": "hvmPLSaPQ5Zp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the Text-to-Image adapter with pre-trained settings optimized for sketch outputs\n",
    "adapter = T2IAdapter.from_pretrained(\n",
    "    \"TencentARC/t2i-adapter-sketch-sdxl-1.0\", torch_dtype=torch.float16, varient=\"fp16\"\n",
    ").to('cuda')  # Move the adapter to GPU to leverage faster computing\n",
    "\n",
    "# Load the scheduler used for controlling the diffusion process\n",
    "model_id = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
    "euler_a = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "\n",
    "# Load the variational autoencoder which refines the image quality\n",
    "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
    "\n",
    "# Assemble the components into a pipeline configured for generating images\n",
    "pipeline = StableDiffusionXLAdapterPipeline.from_pretrained(\n",
    "    model_id, vae=vae, adapter=adapter, scheduler=euler_a, torch_dtype=torch.float16, variant=\"fp16\",\n",
    ").to('cuda')\n",
    "\n",
    "# Load the PidiNet Detector for enhancing detection and conditioning capabilities in generated images\n",
    "pidinet = PidiNetDetector.from_pretrained(\"lllyasviel/Annotators\").to('cuda')\n"
   ],
   "metadata": {
    "id": "rxc9Jkq6SAZO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we move into image handling and drawing within this notebook, we import essential libraries for uploading, displaying, and manipulating images:\n",
    "\n",
    "- **`from google.colab import output`**: Manages interactive outputs in Google Colab.\n",
    "- **`from IPython.display import HTML, display`**: Embeds media like images and HTML for dynamic content presentation.\n",
    "- **`from PIL import Image, ImageDraw, ImageFont, ImageOps`**: Offers comprehensive tools for image processing and manipulation.\n",
    "- **`import base64`**: Encodes and decodes binary data to ASCII, useful for embedding images in text formats.\n",
    "- **`import io`**: Manages binary data streams, crucial for in-memory image operations.\n",
    "- **`import matplotlib.pyplot as plt`**: Provides tools for creating visualizations, used here to display and analyze images.\n",
    "\n",
    "These libraries form the backbone of our image interaction capabilities, facilitating both basic and advanced image tasks in the workshop.\n"
   ],
   "metadata": {
    "id": "dyMXqljkUXut"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvBreODDuU_n"
   },
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "import base64\n",
    "import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following script downloads images from specified URLs and saves them into the Colab content folder. It uses `wget` for downloading. A dictionary `images` maps file names to URLs. The script iterates over this dictionary, downloading each image. Finally, it lists the files in the `/content` directory to confirm the downloads."
   ],
   "metadata": {
    "id": "wjpqx7ULMjOB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import wget          #used for downloading files from the web.\n",
    "\n",
    "# Download the images from web into colab content folder\n",
    "# Define the URLs and corresponding file names for the images\n",
    "images = {\n",
    "    \"flower-woman.jpg\": \"https://github.com/BFH-AMI/sds24/raw/main/Workshop1/images/flower-woman.jpg\",\n",
    "    \"choice.jpg\": \"https://github.com/BFH-AMI/sds24/raw/main/Workshop1/images/choice.jpg\",\n",
    "    \"chaotic-woman.jpg\": \"https://github.com/BFH-AMI/sds24/raw/main/Workshop1/images/chaotic-woman.jpg\"\n",
    "}\n",
    "\n",
    "# Download each image using wget\n",
    "for filename, url in images.items():\n",
    "    wget.download(url, out=f'/content/{filename}')\n",
    "\n",
    "# List the files to confirm download\n",
    "!ls /content"
   ],
   "metadata": {
    "id": "K16Bpjtx7V1w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to use pictures associated with the persona stories discussed earlier in the notebook,\n",
    "uncomment the desired image path below by removing the '#' at the beginning of the line.\n",
    "\n",
    "Alternatively, if you have drawn a picture yourself and uploaded it to Google Colab,\n",
    "provide the path to your image in the format shown below and uncomment it."
   ],
   "metadata": {
    "id": "NAP9rwR9XOph"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**How to Upload an Image in Google Colab**\n",
    "\n",
    "1. Select and click on the folder icon on the left sidebar.\n",
    "2. Click on the upload icon (a paperclip or arrow pointing upward).\n",
    "3. Browse files from your computer, select the desired image, and upload it.\n"
   ],
   "metadata": {
    "id": "KLzne3ZZK10y"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrhFZDA0t_Qq",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "outputId": "734a1553-c4b7-4a59-fef6-bed8600f43f5"
   },
   "outputs": [],
   "source": [
    "#image_path = '/content/flower-woman.jpg'       # For Emily's Flower-Woman persona story\n",
    "#image_path = '/content/choice.jpg'             # For Mark's Choice persona story\n",
    "image_path = '/content/chaotic-woman.jpg'       # For Linda's Batte with Anxiety persona story\n",
    "#image_path = '/content/your-image-name.extension'   # Replace with your file's name and extension\n",
    "\n",
    "img = Image.open(image_path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Hide axes for cleaner presentation\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "####Drawing Directly in the Notebook"
   ],
   "metadata": {
    "id": "D13rHnGlBG6N"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "In this section, you have the option to create a drawing directly within the notebook using an HTML canvas. This interactive feature allows you to use your mouse to draw freely on a digital canvas embedded in the notebook.\n",
    "\n",
    "**How It Works:**\n",
    "- The canvas is initialized with a white background and set dimensions.\n",
    "- You can begin drawing by pressing and holding the mouse button while moving the cursor over the canvas area.\n",
    "- Once you release the mouse button, the drawing action stops, but you can resume by pressing and holding again.\n",
    "- A 'Save' button is provided below the canvas. Once you are satisfied with your drawing, click this button to save the image. The image is then automatically saved to the notebook's environment as a PNG file and will be displayed below the canvas for you to review.\n"
   ],
   "metadata": {
    "id": "TXU9XzxzYTTO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "######\n",
    "#RUN ONLY IF YOU WANT TO DRAW YOUR SKETCH DIRECTLY IN THE NOTEBOOK\n",
    "######\n",
    "\n",
    "\n",
    "\n",
    "# HTML/JavaScript part\n",
    "canvas_html = \"\"\"\n",
    "\n",
    "<canvas width=\"400\" height=\"300\" style=\"border:1px solid #000000;\"></canvas>\n",
    "<button onclick=\"saveCanvas()\">Save</button>\n",
    "<button onclick=\"clearCanvas()\">Clear</button>\n",
    "<button onclick=\"resizeCanvas(800, 600)\">Large Canvas</button>\n",
    "<button onclick=\"resizeCanvas(400, 300)\">Small Canvas</button>\n",
    "<label for=\"colorPicker\">Color:</label>\n",
    "<input type=\"color\" id=\"colorPicker\">\n",
    "<label for=\"brushSize\">Brush Size:</label>\n",
    "<input type=\"range\" id=\"brushSize\" min=\"1\" max=\"10\" value=\"1\">\n",
    "\n",
    "<script>\n",
    "var canvas = document.querySelector('canvas');\n",
    "var ctx = canvas.getContext('2d');\n",
    "ctx.fillStyle = \"white\";\n",
    "ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "ctx.lineJoin = 'round';\n",
    "ctx.lineCap = 'round';\n",
    "\n",
    "var mouse = {x: 0, y: 0};\n",
    "var last_mouse = {...mouse};\n",
    "var drawing = false;\n",
    "\n",
    "canvas.addEventListener('mousedown', function(e) {\n",
    "    drawing = true;\n",
    "    last_mouse.x = e.pageX - this.offsetLeft;\n",
    "    last_mouse.y = e.pageY - this.offsetTop;\n",
    "    ctx.strokeStyle = document.getElementById('colorPicker').value;\n",
    "    ctx.lineWidth = document.getElementById('brushSize').value;\n",
    "}, false);\n",
    "\n",
    "canvas.addEventListener('mouseup', function() {\n",
    "    drawing = false;\n",
    "}, false);\n",
    "\n",
    "canvas.addEventListener('mousemove', function(e) {\n",
    "    mouse.x = e.pageX - this.offsetLeft;\n",
    "    mouse.y = e.pageY - this.offsetTop;\n",
    "    if (drawing) {\n",
    "        ctx.beginPath();\n",
    "        ctx.moveTo(last_mouse.x, last_mouse.y);\n",
    "        ctx.lineTo(mouse.x, mouse.y);\n",
    "        ctx.stroke();\n",
    "        last_mouse = {...mouse};\n",
    "    }\n",
    "}, false);\n",
    "\n",
    "function saveCanvas() {\n",
    "    var dataURL = canvas.toDataURL('image/png');\n",
    "    var data = dataURL.split(',')[1];\n",
    "    try {\n",
    "        google.colab.kernel.invokeFunction('notebook.save_image', [data], {});\n",
    "        alert('Image saved successfully!');\n",
    "    } catch (error) {\n",
    "        console.error('Failed to save the image:', error);\n",
    "        alert('Failed to save the image. Please try again.');\n",
    "    }\n",
    "}\n",
    "\n",
    "function clearCanvas() {\n",
    "    ctx.fillStyle = \"white\";\n",
    "    ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "}\n",
    "\n",
    "function resizeCanvas(width, height) {\n",
    "    canvas.width = width;\n",
    "    canvas.height = height;\n",
    "    ctx.fillStyle = \"white\";\n",
    "    ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "}\n",
    "</script>\n",
    "\"\"\"\n",
    "# Display the HTML canvas\n",
    "display(HTML(canvas_html))\n",
    "\n",
    "# Function to save the image\n",
    "def save_image(img_str):\n",
    "    # Decode the image string\n",
    "    img_data = base64.b64decode(img_str)\n",
    "    # Convert to a PIL Image\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "    img.save('/content/drawing.png')\n",
    "    # Display the image\n",
    "    display(img)\n",
    "\n",
    "# Register the save function\n",
    "output.register_callback('notebook.save_image', save_image)"
   ],
   "metadata": {
    "id": "tjmhK_s_Y6QQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "######\n",
    "#RUN ONLY IF YOU WANT TO DRAW YOUR SKETCH DIRECTLY IN THE NOTEBOOK\n",
    "######\n",
    "\n",
    "\n",
    "canvas_drawing_path = '/content/drawing.png'\n",
    "canvas_drawing = Image.open(canvas_drawing_path)\n",
    "img = canvas_drawing"
   ],
   "metadata": {
    "id": "8RE3eLvo8nn8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "####Preprocessing the Image with PidiNet Detector"
   ],
   "metadata": {
    "id": "4smYqWwTBBEU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Before using the Text-to-Image (T2I) Adapter, it's crucial to preprocess the image to enhance edge detection, which helps in better interpreting the image's details. This is achieved by using the PidiNet detector.\n",
    "\n",
    "Image Processing Steps:\n",
    "- **Edge Detection**: The PidiNet detector performs edge detection, which is crucial for identifying and highlighting the boundaries and structures within the image.\n",
    "- **Resolution Specifications**:\n",
    "  - `detect_resolution`: This parameter sets the resolution at which the edge detection will be carried out. A higher resolution allows for more detailed edge detection.\n",
    "  - `image_resolution`: This is the resolution to which the image will be resized before processing. Adjusting this can affect the clarity and outcome of the edge detection.\n",
    "- **Applying Filters**: With `apply_filter` set to True, the image undergoes preprocessing such as smoothing or denoising. These filters help reduce noise and improve the clarity of the detected edges, making the features in the image more pronounced and easier for the AI model to interpret.\n",
    "\n",
    "The processed image is then displayed, allowing you to see the effects of these preprocessing steps, and providing a refined input for subsequent AI-driven image generation tasks.\n"
   ],
   "metadata": {
    "id": "NaeqMz2Xo67F"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i2vcc9UyF_U"
   },
   "outputs": [],
   "source": [
    "# Process the image using the PidiNet detector to enhance edge detection\n",
    "processed_image = pidinet(img, detect_resolution=1024, image_resolution=1024, apply_filter=True)\n",
    "\n",
    "# Output the size of the processed image to verify the processing steps\n",
    "print(f\"Processed image size = \", processed_image.size)\n",
    "\n",
    "#Display the processed image\n",
    "display(processed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generating the image"
   ],
   "metadata": {
    "id": "hoYe9msiKIu6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To effectively utilize the T2I adapter in generating images, it is essential to provide both positive and negative prompts. These prompts guide the AI by clearly describing what should and should not be included in the final image, enhancing the relevance and accuracy of the generated visuals.\n",
    "\n",
    "Understanding Prompts:\n",
    "- **Positive Prompts**: Describe the desired elements, themes, and details that you want to appear in the image. This includes specifying colors, atmosphere, objects, and the level of detail.\n",
    "- **Negative Prompts**: Outline what you wish to exclude from the image. These can be elements that might detract from the intended focus or mood of the depiction.\n",
    "\n",
    "**Using Pre-uploaded Images:**\n",
    "- If you are working with one of the pre-uploaded images related to the persona stories earlier in the notebook, example prompts are already provided. These prompts have been tailored to align with the themes and narratives of the corresponding stories.\n",
    "\n",
    "Creating Your Own Prompts:\n",
    "- **For Participants Using Sketches or Canvas Drawings**: If you have created an image using the canvas in the notebook or have uploaded your own sketch, you will need to write your own prompts. This is a crucial step as it allows you to convey the specific emotions and details you envision for your artwork.\n",
    "\n"
   ],
   "metadata": {
    "id": "ql5x68-4s5m5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Implementing the Adapter:"
   ],
   "metadata": {
    "id": "5UPFMKlnA0f3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Once you have your positive and negative prompts ready, you can use them along with the processed image to direct the T2I adapter. The adapter uses these prompts to refine the AI's output, ensuring that the generated image aligns closely with your creative vision.\n",
    "\n",
    "Key Parameters:\n",
    "- **`num_inference_steps`**: Determines the number of steps the model takes to refine the image. More steps can lead to a more detailed and coherent image.\n",
    "- **`adapter_conditioning_scale`**: Controls the degree to which the adapter influences the generation process based on the input image and text prompts. A higher value means stronger adherence to the input conditioning.\n",
    "- **`guidance_scale`**: This parameter adjusts how strictly the model adheres to the text prompts during image generation. A higher value results in stronger guidance, which means the final image will more closely reflect the details and themes described in the prompts. It effectively enhances the creative direction provided by your text, leading to images that closely match the described vision."
   ],
   "metadata": {
    "id": "A7aVyEKLA3eQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTvAK377ygEv"
   },
   "outputs": [],
   "source": [
    "########\n",
    "#IF YOU USED POVIDED IMAGES YOU MAY USE FOLLOWING PROMPTS BY UNCOMMENTING THEM\n",
    "########\n",
    "\n",
    "\n",
    "\n",
    "######\n",
    "#FLOWER-WOMAN\n",
    "#EMILY'S JOURNEY THROUGH ART THERAPY\n",
    "#prompt = \"a head of woman in pot, realistic facial features, ranunculus on her head, representing personal growth and renewal, messy background, detailed, high quality\"\n",
    "#negative_prompt = \"empty pot, low resolution, non-realistic, cool background\"\n",
    "#prompt = \"a pot with a realistic human profile, with a vibrant sunflower on her head, symbolizing blossoming ideas and creativity, detailed high-quality, bright, yellow\"\n",
    "#negative_prompt = \"empty pot, simplistic, cartoonish, low resolution\"\n",
    "#prompt = \"artistic portrayal of a woman's profile in a flowerpot with a flowering plant growing from her head, inspiring background, transformation, detailed and vibrant.\"\n",
    "#negative_prompt = \"static scene, monochrome, simplistic elements, low detail.\"\n",
    "#######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######\n",
    "#CHOICE\n",
    "# MARK'S DESICION-MAKING CROSSROADSM\n",
    "#prompt = \"Man in formal suit, standing at a crossroads, sign reading 'Career' one way, 'Passion' other way, clear paths, thoughtful expression, detailed, high resolution\"\n",
    "#negative_prompt = \"Indistinct man, vague crossroads, no signs, obscured paths, low quality\"\n",
    "#prompt = \"Figure contemplating at a fork in the road, paths labeled 'Here'to office building, 'There' label to music festival, realistic style, detailed, high resolution\"\n",
    "#negative_prompt = \"Unfocused figure, confusing paths, no labels, low quality\"\n",
    "#prompt = \"Businessman at a symbolic crossroad, road sign with 2 directions to office and music festival, detailed, high resolution\"\n",
    "#negative_prompt = \"Vague figure, misleading signs, srene landscape, low quality\"\n",
    "#######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######\n",
    "#CHAOTIC-WOMAN\n",
    "#LINDA'S ANXIETY BATTLE\n",
    "prompt = \"Professional woman in a suit with her face buried in her hands, surrounded by chaotic scribbles representing mental stress and anxiety, detailed, high resolution\"\n",
    "negative_prompt = \"Calm woman, clear background, simple lines, low detail, low resolution\"\n",
    "#prompt = \"Confident woman in business attire with her face in her hands, surrounded by a whirlwind of chaotic lines, symbolizing overwhelming thoughts, high-quality, detailed\"\n",
    "#negative_prompt = \"Relaxed woman, empty background, no chaos, cartoonish, low quality\"\n",
    "#prompt = \"Elegant woman in a tailored suit, face hidden in hands, surrounded by a storm of intersecting lines, embodying the battle with anxiety, artistic, high resolution\"\n",
    "#negative_prompt = \"Casual woman, peaceful expression, simplistic background, no turmoil, low resolution\"\n",
    "#######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######\n",
    "#IF YOU WANT TO USE YOUR OWN PROMOTS UNCOMMENT THESE\n",
    "#######\n",
    "\n",
    "#YOUR OWN IMAGE\n",
    "#prompt = \"\"\n",
    "#negative_prompt = \"\"\n",
    "#######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set a global seed for consistency across runs\n",
    "set_global_seeds(42)\n",
    "\n",
    "# Generate the image using the T2I adapter\n",
    "gen_image = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt = negative_prompt,\n",
    "    image=processed_image,\n",
    "    num_inference_steps=30,\n",
    "    adapter_conditioning_scale=0.7,  # Controls the influence of conditioning on the input\n",
    "    guidance_scale=8,                # Dictates the adherence to the text prompts\n",
    ").images[0]\n",
    "\n",
    "\n",
    "# Save the generated image\n",
    "gen_image.save('T2ISDXL_sketch.png')\n",
    "T2ISDXL_sketch_path = '/content/T2ISDXL_sketch.png'\n",
    "print(f\"Image saved successfully at {T2ISDXL_sketch_path}\")\n",
    "\n",
    "\n",
    "# Display the saved image\n",
    "plt.imshow(gen_image)\n",
    "plt.axis('off')  # Hide axes for cleaner presentation\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visual Comparison of Original and Generated Images"
   ],
   "metadata": {
    "id": "SWGXGPsaAc5K"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "In this section, we will display both the original image selected or uploaded by you and the image generated by the AI model side by side. This visual comparison helps illustrate how the positive and negative prompts influenced the final generated image, providing a clear example of the AI model's interpretative capabilities its creative potential.\n"
   ],
   "metadata": {
    "id": "uTiidezNJ-ko"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "######\n",
    "#FOR VISUAL COMPARISON OF THE RESULTS UNCOMMENT OR PROVIDE A CORRECT PASS TO THE ORIGINAL IMAGE\n",
    "######\n",
    "\n",
    "\n",
    "\n",
    "# Define paths to the original and generated images\n",
    "#original_image_path = '/content/flower-woman.jpg'      # FLOWER-WOMAN\n",
    "#original_image_path = '/content/choice.jpg'            # CHOICE\n",
    "original_image_path = '/content/chaotic-woman.jpg'      #CHAOTIC-WOMAN\n",
    "#original_image_path = '/content/drawing.png'           #IF USED DRAWABLE CANVAS\n",
    "#original_image_path = '/content/your-image-name.extension'    #IF YOU UPLOADED YOUR OWN IMAGE\n",
    "\n",
    "\n",
    "generated_image_path = T2ISDXL_sketch_path\n",
    "\n",
    "\n",
    "# Load the images\n",
    "original_img = Image.open(original_image_path)\n",
    "generated_img = Image.open(generated_image_path)\n",
    "\n",
    "# Create a figure to display both images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(original_img)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')  # Hide axes ticks\n",
    "\n",
    "ax[1].imshow(generated_img)\n",
    "ax[1].set_title('Generated Image')\n",
    "ax[1].axis('off')  # Hide axes ticks\n",
    "\n",
    "# Place a text box in bottom left in axes coords for the prompts\n",
    "textstr = f\"Positive Prompt: {prompt}\\nNegative Prompt: {negative_prompt}\"\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "fig.text(0.5, 0.02, textstr, fontsize=12, verticalalignment='bottom', horizontalalignment='center', bbox=props)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "Fxt9kHEpKZJf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GPU Memory Management in Google Colab\n"
   ],
   "metadata": {
    "id": "yCWnbbrMAgQo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "When working with deep learning models in PyTorch within Google Colab, managing GPU memory effectively is crucial to prevent crashes due to memory overflow.\n",
    "\n",
    "Steps to release GPU memory after heavy computations:\n",
    "1. **Delete Models and Variables:** Explicitly remove models and large variables to free their memory.\n",
    "2. **Run Garbage Collection:** Use `gc.collect()` to eliminate unused or unreferenced objects from memory.\n",
    "3. **Clear CUDA Cache:** Execute` torch.cuda.empty_cache() `to clear cached memory that is no longer in use.\n",
    "4. **Check Memory Status** (Optional): Print a memory summary with torch.cuda.memory_summary() to verify that memory has been freed and to understand how memory is allocated.\n",
    "\n",
    "These steps ensure your Colab sessions run smoothly and efficiently, even after processing intensive tasks.\n",
    "\n"
   ],
   "metadata": {
    "id": "Ed37sONjONRH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#library responsible for garbige collection\n",
    "import gc\n",
    "\n",
    "# 'adapter', 'pipe', 'pidinet', 'vae', and 'euler_a' are T2I Adapter SDXL model components\n",
    "del adapter\n",
    "del pipeline\n",
    "del pidinet\n",
    "del vae\n",
    "del euler_a"
   ],
   "metadata": {
    "id": "WC8WXx1aO4sf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Collect garbage to free up memory from deleted objects\n",
    "gc.collect()"
   ],
   "metadata": {
    "id": "V4xZ-CWfouku"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "id": "Y_0z_Royoxcv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Optionally, confirm CUDA memory status\n",
    "print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "id": "aeeGXkSqpBZj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Discussing and Modifying the Artwork Using AI Inpainting\n"
   ],
   "metadata": {
    "id": "4JEQV9_DXOM-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In traditional art therapy, this stage involves the patient and therapist discussing the completed artwork. This discussion aims to understand and interpret the emotions and thoughts represented in the artwork. Key areas of focus include:\n",
    "\n",
    "- **Exploration**: \"What is going on in this image? What do I notice? What do I feel?\"\n",
    "- **Evaluation**: \"What elements of the artwork do I like or dislike? What changes might better convey my feelings or ideas?\"\n",
    "\n",
    "Based on this reflective dialogue, modifications might be desired to further explore or express these insights. Typical modifications could include overpainting, rearranging elements, cropping, or starting anew, allowing for creative exploration of potential solutions or expressions.\n",
    "\n",
    "**Using Generative AI for Modification**\n",
    "\n",
    "In our digital simulation, we demonstrate the potential of generative AI to facilitate these artistic modifications:\n",
    "1. **Identify Changes**: Decide which parts of the image should be changed based on the therapeutic discussion.\n",
    "2. **Text Input for Inpainting**: Utilize example texts or input your own descriptions for the desired changes.\n",
    "3. **Apply Inpainting**: Mask the areas of the image to be adjusted and use inpainting to modify them based on the provided prompts.\n"
   ],
   "metadata": {
    "id": "-5SWalF0XMTG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Understanding Inpainting"
   ],
   "metadata": {
    "id": "h2pOXtmRARn1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Inpainting is a digital technique used to reconstruct missing or damaged parts of images, making the filled areas indistinguishable from the original. This involves several steps:\n",
    "\n",
    "1. **Masking**: The area to be restored is identified and masked.\n",
    "2. **Context Analysis**: The AI analyzes the surrounding image to understand the context, including textures, colors, and patterns.\n",
    "3. **Texture Synthesis**: Using generative models trained on extensive image datasets, the AI synthesizes texture that matches the surrounding area.\n",
    "4. **Refinement**: The new section is refined to blend seamlessly with the entire image.\n",
    "\n",
    "**Applications in Art Therapy**\n",
    "\n",
    "In art therapy, AI-powered inpainting allows clients to modify their artwork digitally. This process supports creative exploration and emotional expression by enabling changes that reflect evolving emotional insights without permanently altering the original artwork. Clients can experiment with different artistic changes easily, facilitating deeper engagement with their creative expression.\n"
   ],
   "metadata": {
    "id": "U7kJzoDFYnq_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Implementing Inpainting with Diffusers Library\n"
   ],
   "metadata": {
    "id": "d6DT086iCaEQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The following Python code uses the `diffusers` library to set up an inpainting pipeline. This setup allows us to apply AI-powered inpainting to images, which is particularly useful in our art therapy simulation.\n",
    "\n",
    "**Importing Necessary Modules**:\n",
    "   - `AutoPipelineForInpainting`: This function from the `diffusers` library loads a pre-trained inpainting model. It's designed to handle the process of masking and generating the inpainted output.\n",
    "   - `load_image`: A utility to load images into a format that can be processed by the pipeline.\n",
    "\n"
   ],
   "metadata": {
    "id": "Ww6JyZl9ZyP5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from diffusers import AutoPipelineForInpainting\n",
    "from diffusers.utils import load_image"
   ],
   "metadata": {
    "id": "M8fQG7X2kLzn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####Setting Up the Inpainting Pipeline"
   ],
   "metadata": {
    "id": "8EUrlBRdACMx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The code below initializes the AI-powered inpainting pipeline using a pre-trained model:\n",
    "\n",
    "- **Model Loading**: We load the model named \"kandinsky-community/kandinsky-2-2-decoder-inpaint\" from the Hugging Face model hub. This model is specifically trained for inpainting tasks and can intelligently regenerate missing parts of images.\n",
    "- **Model Configuration**: The model is configured to use `torch.float16`, which is a data type that uses half-precision floating point for calculations. This setting helps in reducing the model's memory and computational requirements.\n",
    "- **Device Assignment**: The pipeline is assigned to run on a CUDA-enabled GPU (`to('cuda')`). This significantly speeds up the inpainting process by utilizing the GPU's parallel processing capabilities.\n",
    "\n"
   ],
   "metadata": {
    "id": "oyhQwd2Ga5n6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Initializing pipline\n",
    "pipeline = AutoPipelineForInpainting.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-2-decoder-inpaint\", torch_dtype=torch.float16\n",
    ").to('cuda')"
   ],
   "metadata": {
    "id": "YkRYv6fikEG_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#####Image Loading and Preprocessing"
   ],
   "metadata": {
    "id": "Z6oR0La2_85A"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "In this section, we load and prepare an image for the inpainting task:\n",
    "\n",
    "- **Image Path Setup**: We specify the path to the image file, `T2ISDXL_sketch_canvas_1.png`, which is stored in the `/content` directory.\n",
    "- **Image Loading**: The image is opened using Python's `Image` module from the PIL (Pillow) library, which provides extensive file format support and powerful image processing capabilities.\n",
    "- **Image Resizing**: To ensure consistency and optimize processing, the image is resized to 1024x1024 pixels.\n",
    "- **Image Dimensions**: We retrieve and store the dimensions of the resized image, which are useful for any processing that depends on the image size.\n",
    "- **Image Encoding to Bytes**: The image is converted into a bytes format, which is a necessary step for encoding the image into a format that can be transmitted or stored.\n",
    "- **Base64 Encoding**: Finally, the image bytes are encoded into Base64, a text-based format that's used for transmitting binary data over environments that are typically designed to handle text. This encoding is useful for embedding the image data directly into HTML or CSS files, or for sending images over networks where binary data may not be supported.\n",
    "\n",
    "This sequence of operations prepares the image for subsequent use in the inpainting process, ensuring that it is in the correct format and size for the model to process efficiently."
   ],
   "metadata": {
    "id": "fb3m5E7Tbs7E"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the file path for the image to be loaded\n",
    "T2ISDXL_sketch_path = '/content/T2ISDXL_sketch.png'\n",
    "\n",
    "# Open the image file using Pillow's Image module\n",
    "T2ISDXL_sketch = Image.open(T2ISDXL_sketch_path)\n",
    "\n",
    "# Retrieve and store the dimensions of the original image\n",
    "original_width, original_height = T2ISDXL_sketch.size\n",
    "\n",
    "# Determine the aspect ratio of the image\n",
    "aspect_ratio = original_width / original_height\n",
    "\n",
    "# Resize the image based on its aspect ratio\n",
    "if aspect_ratio > 1:\n",
    "    # If the image is horizontal\n",
    "    new_width = 1024\n",
    "    new_height = int(1024 / aspect_ratio)\n",
    "else:\n",
    "    # If the image is quadratic or vertical\n",
    "    new_width = int(1024 * aspect_ratio)\n",
    "    new_height = 1024\n",
    "\n",
    "# Resize the image for consistent processing\n",
    "img = T2ISDXL_sketch.resize((new_width, new_height))\n",
    "\n",
    "# Retrieve and store the dimensions of the resized image\n",
    "image_width, image_height = img.size\n",
    "\n",
    "# Create a buffer to hold the bytes of the image\n",
    "img_bytes = io.BytesIO()\n",
    "\n",
    "# Save the image to the buffer in JPEG format\n",
    "img.save(img_bytes, format='JPEG')\n",
    "\n",
    "# Encode the image bytes to Base64 to facilitate easy text-based storage or transmission\n",
    "img_b64 = base64.b64encode(img_bytes.getvalue()).decode('ascii')\n"
   ],
   "metadata": {
    "id": "WMcO9fN7QAHs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Interactive Image Modification with Drawable Canvas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "JhYlTMaVdL4G"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we implement an interactive canvas within the notebook that allows you to modify an image by drawing directly on it. This feature is particularly useful in art therapy settings, enabling you to explore changes to your artwork in a dynamic and intuitive manner. Below is an explanation of how different masks are used in this process:\n",
    "\n",
    "Canvas and Drawing Functionality\n",
    "- **Canvas Setup**: A canvas is layered over the displayed image, matching its dimensions. This setup allows for precise modifications directly on top of the image.\n",
    "- **Drawing Tools**: You can draw on the canvas using simple mouse actions. The brush color is set to enhance visibility and contrast against the image background.\n",
    "\n",
    "Saving and Processing Drawings\n",
    "- **Saving Modifications**: A 'Save' button captures the content you draw on the canvas. The drawing is then processed using backend Python functions.\n",
    "- **Image Processing**: The drawn content is saved as a PNG image. This image serves as a basis for creating various masks.\n",
    "\n",
    "Mask Creation and Its Roles\n",
    "- **Transparent Mask**: The saved drawing is initially processed to create a transparent mask. This involves setting a transparent background where no drawing is present, allowing the original image to show through the undrawn areas.\n",
    "- **White Background Mask**: To enhance visibility and utility, a white background mask is created by placing the transparent drawing over a white background. This mask highlights the drawn areas distinctly, making them easily identifiable.\n",
    "- **Inverted Mask**: Finally, an inverted mask is created by inverting the colors of the white background mask. This mask is particularly useful for inpainting and other image processing tasks, as it clearly defines which areas need to be modified."
   ],
   "metadata": {
    "id": "rebxTvUo_qBU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "canvas_html = f\"\"\"\n",
    "<div style=\"position: relative; width: {image_width}px; height: {image_height}px;\">\n",
    "  <img src=\"data:image/jpeg;base64,{img_b64}\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\">\n",
    "  <canvas id=\"drawingCanvas\" width=\"{image_width}\" height=\"{image_height}\" style=\"position: absolute; top: 0; left: 0; border:1px solid #000000;\"></canvas>\n",
    "</div>\n",
    "<label>Brush Size:</label>\n",
    "<input type=\"range\" id=\"brushSize\" min=\"1\" max=\"50\" value=\"10\" onchange=\"updateBrushSize()\">\n",
    "<button onclick=\"clearCanvas()\">Clear</button>\n",
    "<button onclick=\"saveCanvas()\">Save</button>\n",
    "<script>\n",
    "var canvas = document.getElementById('drawingCanvas');\n",
    "var ctx = canvas.getContext('2d');\n",
    "var brushSize = 10;  // Initialize brush size\n",
    "var mouse = {{x: 0, y: 0}};\n",
    "var last_mouse = {{x: 0, y: 0}};\n",
    "var drawing = false;\n",
    "\n",
    "// Update brush size\n",
    "function updateBrushSize() {{\n",
    "    brushSize = document.getElementById('brushSize').value;\n",
    "}}\n",
    "\n",
    "// Clear the canvas\n",
    "function clearCanvas() {{\n",
    "    ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
    "}}\n",
    "\n",
    "canvas.addEventListener('mousedown', function(e) {{\n",
    "    drawing = true;\n",
    "    last_mouse.x = e.pageX - this.offsetLeft;\n",
    "    last_mouse.y = e.pageY - this.offsetTop;\n",
    "    ctx.lineWidth = brushSize;\n",
    "}}, false);\n",
    "\n",
    "canvas.addEventListener('mouseup', function() {{\n",
    "    drawing = false;\n",
    "}}, false);\n",
    "\n",
    "canvas.addEventListener('mousemove', function(e) {{\n",
    "    mouse.x = e.pageX - this.offsetLeft;\n",
    "    mouse.y = e.pageY - this.offsetTop;\n",
    "    if (drawing) {{\n",
    "        ctx.beginPath();\n",
    "        ctx.moveTo(last_mouse.x, last_mouse.y);\n",
    "        ctx.lineTo(mouse.x, mouse.y);\n",
    "        ctx.lineWidth = brushSize;\n",
    "        ctx.lineCap = \"round\";\n",
    "        ctx.strokeStyle = \"black\";\n",
    "        ctx.stroke();\n",
    "        last_mouse.x = mouse.x;\n",
    "        last_mouse.y = mouse.y;\n",
    "    }}\n",
    "}}, false);\n",
    "\n",
    "function saveCanvas() {{\n",
    "    var dataURL = canvas.toDataURL('image/png');\n",
    "    var data = dataURL.split(',')[1];\n",
    "    google.colab.kernel.invokeFunction('notebook.save_image', [data], {{}});\n",
    "}}\n",
    "</script>\n",
    "\"\"\"\n",
    "# Display the HTML canvas\n",
    "display(HTML(canvas_html))\n",
    "\n",
    "# Function to save the image and process it for creating a mask\n",
    "def save_image(img_str):\n",
    "    # Decode the image string to binary data\n",
    "    img_data = base64.b64decode(img_str)\n",
    "    # Convert the binary data to a PIL Image\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "    img.save('/content/drawing.png') # Save the initial drawing\n",
    "\n",
    "    # Create and save a new image with a white background\n",
    "    new_img = Image.new('RGBA', img.size, (255, 255, 255, 255))\n",
    "    new_img.save(\"white.png\")\n",
    "\n",
    "    white_image = Image.open('white.png')\n",
    "    transparent_image = img\n",
    "\n",
    "    # Ensure the image is in RGBA format for proper compositing\n",
    "    if transparent_image.mode != 'RGBA':\n",
    "        transparent_image = transparent_image.convert('RGBA')\n",
    "\n",
    "    # Composite the transparent image over the white background\n",
    "    white_image.paste(transparent_image, (0, 0), transparent_image)\n",
    "    white_image = white_image.convert('RGB')\n",
    "\n",
    "    # Invert the image colors to create a mask\n",
    "    inverted_img = ImageOps.invert(white_image)\n",
    "    inverted_img.save('mask_image.png') # Save the final mask\n",
    "    print(\"Mask saved\")\n",
    "    display(inverted_img) # Display the mask image\n",
    "\n",
    "# Register the save function to allow invocation from JavaScript\n",
    "output.register_callback('notebook.save_image', save_image)\n"
   ],
   "metadata": {
    "id": "5uE_D10h7mOI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "drawing = Image.open('/content/T2ISDXL_sketch.png')  #Adjust if needed\n",
    "mask_image = Image.open('/content/mask_image.png')\n",
    "white = Image.open('/content/white.png')\n",
    "\n",
    "# Set up a matplotlib subplot with 3 rows to display the images\n",
    "fig, axs = plt.subplots(2, figsize=(10, 15))  # Adjust figsize to ensure images are not too small\n",
    "\n",
    "# Display the original drawing in the first subplot\n",
    "axs[0].imshow(drawing)\n",
    "axs[0].set_title('Original Drawing')\n",
    "axs[0].axis('off')  # Turn off axis to focus on the image\n",
    "\n",
    "# Display the mask image in the second subplot\n",
    "axs[1].imshow(mask_image)\n",
    "axs[1].set_title('Mask Image')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area.\n",
    "plt.show()  # Show the plots"
   ],
   "metadata": {
    "id": "0mzvgjf7g0OY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Implementing the Inpainting Pipeline\n",
    "\n"
   ],
   "metadata": {
    "id": "6RUGe-QEoLZo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following steps, you'll use the inpainting pipeline to creatively alter parts of your image where you've applied a mask.\n",
    "\n",
    "Below are some example prompts that suggest potential changes to the image. Feel free to use these by uncommenting the desired prompt or create a new one based on your earlier modifications.\n",
    "\n",
    "By setting a seed with `set_global_seeds(42)`, we ensure that the inpainting results are reproducible, yielding consistent outputs each time the pipeline is run with the same settings.\n",
    "\n",
    "With your chosen prompt, the pipeline employs deep learning to intelligently fill in the masked areas. Adjust the `strength` parameter to control the distinction between the inpainted and original areas of the image. The `guidance_scale` parameter determines how closely the inpainting follows the thematic direction set by your prompt.\n"
   ],
   "metadata": {
    "id": "SqkvLVyp_WwR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Example prompts\n",
    "#flower-woman\n",
    "#prompt = \"Woman with a long, flowing hairstyle, adding waves and volume”\n",
    "#prompt = \"Woman with golden, flowing dress, matching style and hue\"\n",
    "#prompt = \"Transform the background into a serene, inspiring natural scene with soft, evening lighting to reflect a calm and nurturing environment for growth.\"\n",
    "\n",
    "\n",
    "#choice\n",
    "#prompt = \"stormy sky, lightning, thunder, pouring, detailed\"\n",
    "#prompt = \"Digital information panel, interactive touch screen, contemporary design\"\n",
    "#prompt = \"Rolling mountain landscape, lush green grass, wildflowers, scenic vista, tranquil nature\"\n",
    "\n",
    "#chaotic-woman\n",
    "# prompt = \"Gentle waterfall flowing from the chaotic lines, clear water symbolizing mental clarity and refreshment\"\n",
    "# prompt = \"Bright galaxy emerging from the scribbles, spiraling arms radiating calm and order, representing Ava's journey to tranquility\"\n",
    "#prompt = \"Glowing lotus blossoming from the tangled lines, petals unfolding smoothly, symbolizing peace and spiritual awakening\"\n",
    "\n",
    "#your prompt\n",
    "prompt = \"stormy sky, lightning, thunder, pouring, detailed\"\n",
    "\n",
    "\n",
    "# Set a consistent seed for reproducibility\n",
    "set_global_seeds(42)\n",
    "\n",
    "\n",
    "#Initiating inpainting pipline\n",
    "image = pipeline(\n",
    "    prompt=prompt,\n",
    "    #negative_prompt=negative_prompt,\n",
    "    image=img,\n",
    "    mask_image=mask_image,\n",
    "    strength= 0.7,               #How seperate the infill is to the rest of the image\n",
    "    guidance_scale = 9,          #How important the prompt is\n",
    "  ).images[0]\n",
    "\n",
    "\n",
    "# Save the generated image\n",
    "image.save('image_inpainting.png')\n",
    "\n",
    "# Save and display the final image with proper size\n",
    "final_image = Image.open('image_inpainting.png')\n",
    "final_image = final_image.resize((new_width, new_height))\n",
    "\n",
    "# Save the final resized image to the content folder\n",
    "final_resized_image_path = '/content/final_resized_image.png'\n",
    "final_image.save(final_resized_image_path)\n",
    "\n",
    "# Display the final resized image (optional)\n",
    "plt.imshow(final_image)\n",
    "plt.axis('off')                              # Hide axes for cleaner presentation\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "YEzl-_7yki-0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visual Comparison of Art Therapy Session Outcomes\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "i8d7gsxULfVG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we'll compare the transformation of images throughout our art therapy session with the use of generative AI. This visual comparison highlights the progression from:\n",
    "\n",
    "1. **Original Image**: The starting artwork.\n",
    "2. **After Applying Adapter**: Modifications by the T2I adapter based on your prompts.\n",
    "3. **Final Inpainted Image**: The end result after  inpainting.\n",
    "\n",
    "By examining these stages side by side, we gain insights into the AI's interpretative capabilities and its effectiveness in enhancing artistic expressions. This comparison serves as a foundation for further discussion."
   ],
   "metadata": {
    "id": "9HSeGCV8_Mlu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "######\n",
    "#FOR VISUAL COMPARISON OF THE RESULTS UNCOMMENT OR PROVIDE A CORRECT PASS TO THE ORIGINAL IMAGE\n",
    "######\n",
    "\n",
    "\n",
    "\n",
    "# Define paths to the original and generated images\n",
    "#original_image_path = '/content/flower-woman.jpg'      # FLOWER-WOMAN\n",
    "#original_image_path = '/content/choice.jpg'            # CHOICE\n",
    "original_image_path = '/content/chaotic-woman.jpg'      #CHAOTIC-WOMAN\n",
    "#original_image_path = '/content/drawing.png'           #IF USED DRAWABLE CANVAS\n",
    "#original_image_path = '/content/your-image-name.extension'    #IF YOU UPLOADED YOUR OWN IMAGE\n",
    "\n",
    "\n",
    "\n",
    "adapted_image_path = '/content/T2ISDXL_sketch.png'  # PATH TO THE IMAGE AFTER APPLYING ADAPTER\n",
    "inpainting_image = '/content/final_resized_image.png'  # PATH TO AFTER INPAINTING IMAGE\n",
    "\n",
    "\n",
    "\n",
    "# Load images using PIL\n",
    "original_img = Image.open(original_image_path)\n",
    "adapted_img = Image.open(adapted_image_path)\n",
    "inpainting_img = Image.open(inpainting_image)\n",
    "\n",
    "# Create a matplotlib figure to display the images\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))  # Setting up a figure with 3 subplots\n",
    "\n",
    "# Display Original Image\n",
    "ax[0].imshow(original_img)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')  # Turn off axis\n",
    "\n",
    "# Display Image after Adapter\n",
    "ax[1].imshow(adapted_img)\n",
    "ax[1].set_title('After Applying Adapter')\n",
    "ax[1].axis('off')  # Turn off axis\n",
    "\n",
    "# Display Final Inpainted Image\n",
    "ax[2].imshow(inpainting_img)\n",
    "ax[2].set_title('Final Inpainted Image')\n",
    "ax[2].axis('off')  # Turn off axis\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "WVPmmDUCMDnx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GPU Memory Cleanup\n",
    "\n",
    "Post-inpainting, it's important to clean up GPU memory to maintain optimal performance. Here’s a quick way to do it:\n"
   ],
   "metadata": {
    "id": "S9rTYKaeOcd2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "del pipeline"
   ],
   "metadata": {
    "id": "fb11oA3POiQB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Collect garbage to free up memory from deleted objects\n",
    "gc.collect()"
   ],
   "metadata": {
    "id": "_e6AjwAr1ns6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "id": "quL48TIg1pEl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Optionally, confirm CUDA memory status\n",
    "print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "id": "jPE0fR-Z1p_Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion and Discussion\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "mZAbZbHaPsk4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We encourage you to experiment with different image prompts and parameters in the generative models we've explored. How might altering these inputs influence the output, and what does this tell us about the interaction between technology and creative expression?\n",
    "\n",
    "To ensure you can continue experimenting without exceeding the GPU usage limits of the platform, remember to manage resources effectively. After each inference test, consider using gc.collect() to run garbage collection and torch.cuda.empty_cache() to clear the CUDA cache. This practice helps in preventing memory overflow and allows for sustained experimentation.\n"
   ],
   "metadata": {
    "id": "WUXp098z_GTI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This workshop has explored the intersection of generative artificial intelligence and well-being through the lens of art. We have demonstrated the capabilities of AI in enhancing creative processes and discussed its implications for well-being. Key takeaways include:\n",
    "\n",
    "- **Enhancement of Creative Expression**: AI tools like the inpainting pipeline provide artists and non-artists alike with the ability to expand their creative boundaries, offering new ways to visualize emotions and concepts.\n",
    "\n",
    "- **Accessibility and Inclusivity**: By automating parts of the creative process, AI can make artistic expression more accessible to individuals who may not have traditional artistic skills, promoting inclusivity.\n",
    "\n",
    "- **Therapeutic Potential**: The act of creating art, assisted by AI, can have therapeutic benefits, helping individuals express themselves in ways that were previously inaccessible to them."
   ],
   "metadata": {
    "id": "WvOM3yGmQmLH"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "S9rTYKaeOcd2",
    "mZAbZbHaPsk4"
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
